{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classfication.ipynb","provenance":[],"authorship_tag":"ABX9TyNdOH7mYAiYhPk6LLaW2Kuf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"acFgruP-kGJD"},"source":["import numpy as np\n","from transformers import BertTokenizer\n","# from transformers import BertForSequenceClassification\n","from transformers.modeling_bert import BertForSequenceClassification\n","import torch\n","from keras.preprocessing.sequence import pad_sequences\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KrYSaJKkPdO"},"source":["if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBI15OK-kTH4"},"source":["#모델 저장된 경로\n","output_dir = './model_save4/'\n","\n","# Load a trained model and vocabulary that you have fine-tuned\n","model = BertForSequenceClassification.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ihjy6SZkbNo"},"source":["def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 512\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3D4rFt4kc4m"},"source":["\n","# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","    inputs = inputs.type(torch.LongTensor)\n","    masks = masks.type(torch.LongTensor)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WGNPAhZXkd_7"},"source":["sentiment_dic = {\n","    0 : 'anger',\n","    1 : 'fear',\n","    2 : 'joy',\n","    3 : 'love',\n","    4 : 'sadness',\n","    5 : 'surprise',\n","}\n","\n","def emotionR(sentence):\n","    # return sentiment_dic[np.argmax(test_sentences([sentence]))]\n","    return 1 + np.argmax(test_sentences([sentence]))"],"execution_count":null,"outputs":[]}]}