{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 993,
     "status": "ok",
     "timestamp": 1600084160172,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "ODHojb63TQYH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "#신영\n",
    "\n",
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3737,
     "status": "ok",
     "timestamp": 1600084162936,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "wdsZ8nnlQcxY",
    "outputId": "9e44231d-388c-4a13-a77c-6343e00dfe66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.4.2-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (17.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (3.7.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (3.0.4)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from transformers) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from importlib-metadata->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\ksy\\appdata\\roaming\\python\\python36\\site-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->transformers) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (6.7)\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.4.2\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face의 트랜스포머 모델을 설치\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: h5py in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\ksy\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 설치_ conda에서 전역 설치 \n",
    "# conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "\n",
    "# 케라스 설치\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5721,
     "status": "ok",
     "timestamp": 1600084164934,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "fqg7ZhReQsMi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5712,
     "status": "ok",
     "timestamp": 1600084164938,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "eE2GezXTQ52x"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"test_data1.tsv\", sep=\"\\t\", header=None, encoding=\"UTF-8\", names=['label','document',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5704,
     "status": "ok",
     "timestamp": 1600084164939,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "QqW2g687k0nA"
   },
   "outputs": [],
   "source": [
    "#중복 제거\n",
    "possible_labels = df.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "df['label'] = df.label.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5695,
     "status": "ok",
     "timestamp": 1600084164940,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "XJVSJyWYQ9-P",
    "outputId": "052f21c3-66b7-453e-84dd-e78b6d15e2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 2)\n",
      "(266, 2)\n"
     ]
    }
   ],
   "source": [
    "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
    "train = df[:1100]\n",
    "test = df[1100:]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5671,
     "status": "ok",
     "timestamp": 1600084164941,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "q3iIgZs7Q-fh",
    "outputId": "e7cca4be-bf0c-450e-b73b-b01b65367139"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>오예 오늘 휴강이다!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘 감기에 걸렸다..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>놀이공원 놀러왔다 신난다! &gt;_&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>아 외롭다..ㅜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>와 진짜 억울하다 프로젝트 다 짰는데 날렸다.... 미친거 아냐?? 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>아싸 시험 100점 ^^</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>오늘 키우던 개가 죽었어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>헐 벌써 4월이야? 시간이 너무 빠르다!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>대박 길 걷다가 만원 주웠다 ㅋㅋㅋ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                    document\n",
       "0      0                               오예 오늘 휴강이다!!!\n",
       "1      1                 사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸\n",
       "2      2                                오늘 감기에 걸렸다..\n",
       "3      0                          놀이공원 놀러왔다 신난다! >_<\n",
       "4      2                                    아 외롭다..ㅜ\n",
       "5      3  와 진짜 억울하다 프로젝트 다 짰는데 날렸다.... 미친거 아냐?? 아...\n",
       "6      0                               아싸 시험 100점 ^^\n",
       "7      2                            오늘 키우던 개가 죽었어...\n",
       "8      4                      헐 벌써 4월이야? 시간이 너무 빠르다!\n",
       "9      0                         대박 길 걷다가 만원 주웠다 ㅋㅋㅋ"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋의 앞부분 출력\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5659,
     "status": "ok",
     "timestamp": 1600084164941,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "w50MJCYtRAGr",
    "outputId": "719639a8-a535-4f63-bd47-9236af4be76d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 오예 오늘 휴강이다!!!\n",
       "1                   사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸\n",
       "2                                  오늘 감기에 걸렸다..\n",
       "3                            놀이공원 놀러왔다 신난다! >_<\n",
       "4                                      아 외롭다..ㅜ\n",
       "5    와 진짜 억울하다 프로젝트 다 짰는데 날렸다.... 미친거 아냐?? 아...\n",
       "6                                 아싸 시험 100점 ^^\n",
       "7                              오늘 키우던 개가 죽었어...\n",
       "8                        헐 벌써 4월이야? 시간이 너무 빠르다!\n",
       "9                           대박 길 걷다가 만원 주웠다 ㅋㅋㅋ\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = train['document']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5650,
     "status": "ok",
     "timestamp": 1600084164942,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "18VFGSyMRDWN",
    "outputId": "ae10bbf5-720c-4069-a0a0-3376d1c7c260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 오예 오늘 휴강이다!!! [SEP]',\n",
       " '[CLS] 사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸 [SEP]',\n",
       " '[CLS] 오늘 감기에 걸렸다.. [SEP]',\n",
       " '[CLS] 놀이공원 놀러왔다 신난다! >_< [SEP]',\n",
       " '[CLS] 아 외롭다..ㅜ [SEP]',\n",
       " '[CLS] 와 진짜 억울하다 프로젝트 다 짰는데 날렸다.... 미친거 아냐?? 아... [SEP]',\n",
       " '[CLS] 아싸 시험 100점 ^^ [SEP]',\n",
       " '[CLS] 오늘 키우던 개가 죽었어... [SEP]',\n",
       " '[CLS] 헐 벌써 4월이야? 시간이 너무 빠르다! [SEP]',\n",
       " '[CLS] 대박 길 걷다가 만원 주웠다 ㅋㅋㅋ [SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5641,
     "status": "ok",
     "timestamp": 1600084164944,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "QR-aMz19eiWH",
    "outputId": "be5793d6-d37a-43c6-d326-0af8a4f0ca31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    498\n",
       "2    233\n",
       "3    120\n",
       "6    115\n",
       "4     79\n",
       "1     37\n",
       "5     17\n",
       "7      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5632,
     "status": "ok",
     "timestamp": 1600084164945,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "0cIDJgLJRFEG",
    "outputId": "8a8ccbf0-bfd3-4064-abc9-c6fa965969a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 0, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = train['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6291,
     "status": "ok",
     "timestamp": 1600084165613,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "XYn9tP8uRGJE",
    "outputId": "f4779a91-fd04-4e55-c5e1-5cb5c7dbec07"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095c494e604047cbacd2dcb79d4d90d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ef31d1a59d46988ad6b7ceaafd0e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c9abb5cb864d1baf5534317ba9007a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 오예 오늘 휴강이다!!! [SEP]\n",
      "['[CLS]', '오', '##예', '오', '##늘', '휴', '##강', '##이다', '!', '!', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6282,
     "status": "ok",
     "timestamp": 1600084165614,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "-md9r8FiRH4T",
    "outputId": "b4c90f9a-de5f-4b27-df7f-807e6261054a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9580,  96279,   9580, 118762,  10013,  47181,  11925,\n",
       "          106,    106,    106,    102,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 256\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6275,
     "status": "ok",
     "timestamp": 1600084165616,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "UStVfFcYRJW4",
    "outputId": "55f0e2a6-7cca-4d13-fc07-0ec8926890aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6731,
     "status": "ok",
     "timestamp": 1600084166082,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "RcSdxKQDRL_E",
    "outputId": "4df8311e-5567-47b5-b7e0-8a2c1ebed316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9580, 118762,   8985,  49212,   9004,  32537,   9685,  11903,\n",
      "           106,    106,    106,   9113,  48446,  12965,   9360,  10739,   9594,\n",
      "         16439, 106154,   9389,  12692,   9343, 118691,   9946,  14867,   9685,\n",
      "        118632,  11903,    100,   9429, 118873,  11903,    106,    102,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0], dtype=torch.int32)\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([  101,  8996, 18392, 12092,  9954, 31720, 28188,  9666, 80331,  9316,\n",
      "        10003, 14279,  9694, 24989, 10530, 19653,  9960, 48549,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0], dtype=torch.int32)\n",
      "tensor(6)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 훈련셋과 검증셋으로 분리\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
    "                                                                                    labels, \n",
    "                                                                                    random_state=41, \n",
    "                                                                                    test_size=0.1)\n",
    "\n",
    "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
    "                                                       input_ids,\n",
    "                                                       random_state=41, \n",
    "                                                       test_size=0.1)\n",
    "\n",
    "# 데이터를 파이토치의 텐서로 변환\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "print(train_inputs[0])\n",
    "print(train_labels[0])\n",
    "print(train_masks[0])\n",
    "print(validation_inputs[0])\n",
    "print(validation_labels[0])\n",
    "print(validation_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6722,
     "status": "ok",
     "timestamp": 1600084166083,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "xSNEPA_qSNHC"
   },
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6716,
     "status": "ok",
     "timestamp": 1600084166084,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "VQPbCHh5SPM2",
    "outputId": "bdeb17b0-7bca-43a1-a9e8-c8104a284aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100                                           수고했어, 지훈아!\n",
       "1101                         행복요정이라더니..행복(부수기)요정인가...?(환장\n",
       "1102         ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ ㅁㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이것이 흥개님의 사랑법,,♡ \n",
       "1103    까우와 까우맘이 좋아해 가끔 부산에 출장 갈 때마다한번도 잊지 않고 어묵을 산 곳인...\n",
       "1104                     헐.. 메일 보내셨구나.. 메일 귀찮아서 안보냈어요 ㅋㅋㅋ\n",
       "1105              ㅌㅌㅋㅋ몽이가일케기엽ㅂ습니다..자식자랑나라사랑..(저유령계정댓나바요ㅠ \n",
       "1106                   헐 당연하죠😊🙏🙏 꼬옥 남겨줄테니 다음에도 찍어주기~~~^^🤙\n",
       "1107                         헐 슬로건ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㄴㅋㄴㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
       "1108    ㅠㅠㅠㅠㅠㅠ 아 개 넘한 ㅠㅠㅠㅠㅠㅠㅠㅠㅠ 헐 ㅠㅠㅠㅠㅠㅠ 아 진짜 넘해요,,,,,...\n",
       "1109                            헉헉헉 대박!!! 박성진!! 깜짝 놀랐어😨😨 \n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 문장 추출\n",
    "sentences = test['document']\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6707,
     "status": "ok",
     "timestamp": 1600084166085,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "wz_qQ8JxSQey",
    "outputId": "1b92f6ea-6063-4f7b-d238-2788ec3a58bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 수고했어, 지훈아! [SEP]',\n",
       " '[CLS] 행복요정이라더니..행복(부수기)요정인가...?(환장 [SEP]',\n",
       " '[CLS] ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ ㅁㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이것이 흥개님의 사랑법,,♡  [SEP]',\n",
       " '[CLS] 까우와 까우맘이 좋아해 가끔 부산에 출장 갈 때마다한번도 잊지 않고 어묵을 산 곳인데.. 이제는 이런 소소한 행복과 추억 마저 안녕이네... ㅜ.  [SEP]',\n",
       " '[CLS] 헐.. 메일 보내셨구나.. 메일 귀찮아서 안보냈어요 ㅋㅋㅋ [SEP]',\n",
       " '[CLS] ㅌㅌㅋㅋ몽이가일케기엽ㅂ습니다..자식자랑나라사랑..(저유령계정댓나바요ㅠ  [SEP]',\n",
       " '[CLS] 헐 당연하죠😊🙏🙏 꼬옥 남겨줄테니 다음에도 찍어주기~~~^^🤙 [SEP]',\n",
       " '[CLS] 헐 슬로건ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㄴㅋㄴㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ [SEP]',\n",
       " '[CLS] ㅠㅠㅠㅠㅠㅠ 아 개 넘한 ㅠㅠㅠㅠㅠㅠㅠㅠㅠ 헐 ㅠㅠㅠㅠㅠㅠ 아 진짜 넘해요,,,,,,ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ [SEP]',\n",
       " '[CLS] 헉헉헉 대박!!! 박성진!! 깜짝 놀랐어😨😨  [SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT의 입력 형식에 맞게 변환\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6695,
     "status": "ok",
     "timestamp": 1600084166085,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "8Gl0ur-zSRVj",
    "outputId": "a0b85fef-93b5-44e5-c319-66b589e1bf3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 0, 0, 0, 2, 4, 0, 2, 0, 1, 2, 2, 0, 0, 4, 0, 6, 4,\n",
       "       2, 4, 3, 4, 4, 3, 2, 1, 2, 4, 1, 0, 0, 4, 0, 0, 0, 2, 4, 4, 2, 0,\n",
       "       0, 0, 2, 0, 2, 0, 3, 2, 0, 0, 0, 4, 3, 1, 2, 3, 2, 0, 6, 0, 2, 0,\n",
       "       3, 6, 0, 3, 3, 2, 6, 3, 0, 2, 0, 6, 1, 2, 3, 3, 2, 3, 6, 3, 0, 2,\n",
       "       3, 0, 3, 2, 3, 3, 2, 2, 2, 3, 6, 4, 0, 0, 0, 0, 2, 4, 2, 6, 1, 2,\n",
       "       0, 4, 4, 4, 2, 1, 1, 6, 0, 0, 2, 1, 0, 2, 6, 4, 6, 0, 0, 6, 6, 6,\n",
       "       0, 0, 0, 0, 0, 0, 0, 5, 0, 2, 4, 2, 0, 2, 1, 4, 6, 6, 4, 4, 4, 1,\n",
       "       6, 1, 6, 6, 2, 0, 0, 0, 6, 0, 4, 4, 4, 4, 2, 1, 2, 0, 0, 4, 1, 2,\n",
       "       4, 2, 0, 3, 0, 0, 2, 0, 3, 2, 6, 0, 2, 0, 2, 0, 0, 4, 1, 5, 6, 0,\n",
       "       6, 4, 3, 3, 6, 0, 2, 0, 2, 0, 6, 0, 3, 3, 0, 3, 2, 6, 2, 0, 2, 0,\n",
       "       3, 0, 6, 0, 0, 3, 2, 2, 2, 3, 0, 0, 0, 2, 6, 2, 2, 2, 2, 0, 0, 0,\n",
       "       2, 3, 6, 0, 6, 0, 3, 2, 0, 3, 6, 0, 2, 0, 0, 1, 5, 3, 3, 2, 0, 4,\n",
       "       6, 3], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라벨 추출\n",
    "labels = test['label'].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7025,
     "status": "ok",
     "timestamp": 1600084166425,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "_st0uoGKSS28",
    "outputId": "10ed994d-1143-48e0-f8b5-3a5eb9c13c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 수고했어, 지훈아! [SEP]\n",
      "['[CLS]', '수', '##고', '##했', '##어', ',', '지', '##훈', '##아', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "print (sentences[0])\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7017,
     "status": "ok",
     "timestamp": 1600084166427,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "KGBtMoriSUOU",
    "outputId": "7b5b1b65-7343-434f-e940-f5826bf49430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,   9460,  11664, 119424,  12965,    117,   9706,  75965,\n",
       "        16985,    106,    102,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 토큰의 최대 시퀀스 길이\n",
    "MAX_LEN = 128\n",
    "\n",
    "# 토큰을 숫자 인덱스로 변환\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7008,
     "status": "ok",
     "timestamp": 1600084166428,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "x8pDSI1rSVlO",
    "outputId": "31f79f0a-004e-4944-8ac9-848ff58a1abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 마스크 초기화\n",
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6998,
     "status": "ok",
     "timestamp": 1600084166429,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "bE7PFCCESWyq",
    "outputId": "ede92816-4412-4a2e-f9d0-00be38a77449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   101,   9460,  11664, 119424,  12965,    117,   9706,  75965,  16985,\n",
      "           106,    102,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0], dtype=torch.int32)\n",
      "tensor(0)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 파이토치의 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "print(test_inputs[0])\n",
    "print(test_labels[0])\n",
    "print(test_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6990,
     "status": "ok",
     "timestamp": 1600084166431,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "HTgIqO2jSYoC"
   },
   "outputs": [],
   "source": [
    "# 배치 사이즈\n",
    "batch_size = 32\n",
    "\n",
    "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
    "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk0l3-WeSar9"
   },
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7846,
     "status": "ok",
     "timestamp": 1600084167294,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "LUEkLs2sSbv4",
    "outputId": "31dc2407-bdd6-4c4d-ffda-6825f209513a"
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8c2f2159c4e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "# GPU 디바이스 이름 구함\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# GPU 디바이스 이름 검사\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7839,
     "status": "ok",
     "timestamp": 1600084167296,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "5zt285RuSrqj",
    "outputId": "bb35a4ad-3d89-4c3d-c660-dd4a3fa2e260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17753,
     "status": "ok",
     "timestamp": 1600084177220,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "isxDW-RvStNV",
    "outputId": "644cf4c3-bf30-4bba-ec68-523e6e2398d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffee593fd974dac9d7321f2898e2618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57f3128e8f0421b9b5b2c28a3833c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e95acaeac193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 분류를 위한 BERT 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bert-base-multilingual-cased\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \"\"\"\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \"\"\"\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# 분류를 위한 BERT 모델 생성\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(label_dict))\n",
    "model.cuda()\n",
    "\n",
    "# coda 없이 학습하는 방법 알아내기 과제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17745,
     "status": "ok",
     "timestamp": 1600084177221,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "LKk1qy5zSwAF"
   },
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률\n",
    "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXi3W-ALTc6r"
   },
   "source": [
    "모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17738,
     "status": "ok",
     "timestamp": 1600084177221,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "W_Ar-hy4SyhD"
   },
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17733,
     "status": "ok",
     "timestamp": 1600084177222,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "RX9oDjIKS1wE"
   },
   "outputs": [],
   "source": [
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 207550,
     "status": "ok",
     "timestamp": 1600084367045,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "8QGZdNf6S3NM",
    "outputId": "02ac18b4-93a2-4c6a-da34-1918cedb6407"
   },
   "outputs": [],
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 19\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84s_uS8JTHDK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209740,
     "status": "ok",
     "timestamp": 1600084369245,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "ptxqyY5iTD1e",
    "outputId": "73ede12f-8c6c-4eb8-b71c-6714320caff4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzSkwqGnTLiG"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209729,
     "status": "ok",
     "timestamp": 1600084369246,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "xOOD0xZRTEQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209722,
     "status": "ok",
     "timestamp": 1600084369247,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "X0R53ru8TO-r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209715,
     "status": "ok",
     "timestamp": 1600084369247,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "_hc0cPreri5R",
    "outputId": "421c33af-fc91-450b-d110-d2043d40f37a"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209706,
     "status": "ok",
     "timestamp": 1600084369248,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "6OUXfR68cAGF",
    "outputId": "faed957d-3be7-4666-ba60-7038f854f1ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209697,
     "status": "ok",
     "timestamp": 1600084369249,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "VpyWLqjXTRfc",
    "outputId": "1bc5b25a-6635-462e-cedc-8c0ffaba4366"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209688,
     "status": "ok",
     "timestamp": 1600084369250,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "0A5zCULZ2GcP",
    "outputId": "a844978b-aa32-4246-d542-ea27c5ec06ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209679,
     "status": "ok",
     "timestamp": 1600084369250,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "lVO4OlrgZEWX",
    "outputId": "64887511-e0e4-4be7-a109-e07fb8427679"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209670,
     "status": "ok",
     "timestamp": 1600084369251,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "WEQKZDTCZE3n",
    "outputId": "3f612f30-746d-4f78-dcb3-0dc4c1961a8a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209661,
     "status": "ok",
     "timestamp": 1600084369252,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "cTx_drh4ZFrq",
    "outputId": "1351b58f-7844-4098-b350-e5480a639b64"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 209653,
     "status": "ok",
     "timestamp": 1600084369253,
     "user": {
      "displayName": "김신영",
      "photoUrl": "",
      "userId": "11478318935090756381"
     },
     "user_tz": -540
    },
    "id": "bNEa4ypRZG3R",
    "outputId": "90981698-2fc2-4595-d7c7-f5045e89fd73"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMO2+HtmzrEvXIeP7Q3andz",
   "collapsed_sections": [],
   "name": "Berk_emotion_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
