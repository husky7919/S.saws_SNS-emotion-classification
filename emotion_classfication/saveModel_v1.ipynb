{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"saveModel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-FyFZdwbhuvx4ycRXgWtti0jdXbkiZ52","authorship_tag":"ABX9TyN4lI911WE5QyAzDBLNK2Ut"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sMuVMupZ2MCl","executionInfo":{"status":"ok","timestamp":1621264536135,"user_tz":-540,"elapsed":1436,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["\n","import pandas as pd\n","import re"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581},"id":"fPLTa5bl2OON","executionInfo":{"status":"ok","timestamp":1621264536136,"user_tz":-540,"elapsed":1218,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"a440bb7d-95d6-4c27-8b60-6983f880eac3"},"source":["# tag_live 크롤링.\n","df = pd.read_csv(\"/content/drive/My Drive/캡스톤디자인/tag_live_hs.csv\", sep=\",\", header=None,encoding=\"cp949\")\n","\n","# 칼럼 이름 변경\n","df.columns = [\"sentiment\",\"text\"]\n","\n","# 칼럼 위치 변경\n","# df = df[[ \"sentiment\" ,\"text\"]]\n"," \n"," # None 값 제거\n","df = df.dropna()\n","df.info()\n","df"],"execution_count":30,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 659 entries, 0 to 658\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   sentiment  659 non-null    object\n"," 1   text       659 non-null    object\n","dtypes: object(2)\n","memory usage: 15.4+ KB\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>surprise</td>\n","      <td>고급진 아..기절기절.. 샤워하고 있는데 난리난리~~ 갑자기 엄마~~!!!!!! 큰...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>surprise</td>\n","      <td>당신이 잠든 사이에~ 남편이 잘 때 옆에서 잠깐 핸드폰으로 메일 정리 하고 인스타를...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>surprise</td>\n","      <td>월요일 아침부터 비가 내리네요 가물다고 하는데 단비가 되었는지... 코로나 환자는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>surprise</td>\n","      <td>오늘 우리 둘째랑 신나게 웃으며 놀다가 갑자기 입천장 쪽에 뭔가 동그랗게 데인것처럼...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>surprise</td>\n","      <td>쇼파에 앉아서 뒤에 몰래찍엇는데 ㅎ 카메라캐치~ 근데 표정이 왜이렇게 므흣한 표정으...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>654</th>\n","      <td>joy</td>\n","      <td>아름다운 행동은 아름다운 자태보다 낫습니다. 아름다운 행동은 조각상이나 그림보다 더...</td>\n","    </tr>\n","    <tr>\n","      <th>655</th>\n","      <td>joy</td>\n","      <td>퇴근길에 구름이 이뻐서 찍고 밤하늘 달이 이뻐서 찍고 초록초록 나무가 이뻐서찍고 사...</td>\n","    </tr>\n","    <tr>\n","      <th>656</th>\n","      <td>joy</td>\n","      <td>주말여행 대전 1박2일 맛있는거 먹고, 쇼핑 반지, 팔찌도 맞추고 옷도사고 수다수다...</td>\n","    </tr>\n","    <tr>\n","      <th>657</th>\n","      <td>joy</td>\n","      <td>권도윤네가 병지방에서 캠핑해서 급으로 꼽사리갔던날인데 애들 왜케 작고 귀여워 저날 ...</td>\n","    </tr>\n","    <tr>\n","      <th>658</th>\n","      <td>joy</td>\n","      <td>즐거운 하루였어요!! 원더풀 밥상에 꼭 먹어야 메뉴는 순두부찌개하고 해물파전이에요!...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>659 rows × 2 columns</p>\n","</div>"],"text/plain":["    sentiment                                               text\n","0    surprise  고급진 아..기절기절.. 샤워하고 있는데 난리난리~~ 갑자기 엄마~~!!!!!! 큰...\n","1    surprise  당신이 잠든 사이에~ 남편이 잘 때 옆에서 잠깐 핸드폰으로 메일 정리 하고 인스타를...\n","2    surprise  월요일 아침부터 비가 내리네요 가물다고 하는데 단비가 되었는지... 코로나 환자는 ...\n","3    surprise  오늘 우리 둘째랑 신나게 웃으며 놀다가 갑자기 입천장 쪽에 뭔가 동그랗게 데인것처럼...\n","4    surprise  쇼파에 앉아서 뒤에 몰래찍엇는데 ㅎ 카메라캐치~ 근데 표정이 왜이렇게 므흣한 표정으...\n","..        ...                                                ...\n","654       joy  아름다운 행동은 아름다운 자태보다 낫습니다. 아름다운 행동은 조각상이나 그림보다 더...\n","655       joy  퇴근길에 구름이 이뻐서 찍고 밤하늘 달이 이뻐서 찍고 초록초록 나무가 이뻐서찍고 사...\n","656       joy  주말여행 대전 1박2일 맛있는거 먹고, 쇼핑 반지, 팔찌도 맞추고 옷도사고 수다수다...\n","657       joy  권도윤네가 병지방에서 캠핑해서 급으로 꼽사리갔던날인데 애들 왜케 작고 귀여워 저날 ...\n","658       joy  즐거운 하루였어요!! 원더풀 밥상에 꼭 먹어야 메뉴는 순두부찌개하고 해물파전이에요!...\n","\n","[659 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xK7JNinO2urv","executionInfo":{"status":"ok","timestamp":1621264536137,"user_tz":-540,"elapsed":983,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"cae645fe-2ee9-4623-dacb-3e1f2b3b8b55"},"source":["df.sentiment.value_counts()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sadness     192\n","joy         191\n","anger        97\n","love         66\n","surprise     57\n","fear         56\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RiKHo4u2upR","executionInfo":{"status":"ok","timestamp":1621264536138,"user_tz":-540,"elapsed":748,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"4032a438-948f-4b10-f47c-aafd2e9923c0"},"source":["df.sentiment.unique()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['surprise', 'fear', 'anger', 'love', 'sadness', 'joy'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"pj89XWnt2um8","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1621264536645,"user_tz":-540,"elapsed":1007,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"5f53eac9-cd9a-4742-bde3-adbf641dcee1"},"source":["# 빌려온 csv파일\n","df1 = pd.read_csv(\"/content/drive/My Drive/캡스톤디자인/test_data1.tsv\", sep=\"\\t\", header=None, encoding=\"UTF-8\")\n","df1.columns = [\"sentiment\", \"text\"]\n","\n","df1 = df1[[\"text\", \"sentiment\"]]\n","df1 = df1.dropna()\n","\n","#neutral 행 제거\n","idx_nm_neutral= df1[df1['sentiment'] == 'neutral'].index\n","df999 = df1.drop(idx_nm_neutral)\n","\n","# 잘못 표기된 'anger ' 행 제거\n","idx_nm_angerErr= df999[df999['sentiment'] == 'anger '].index\n","df1 = df999.drop(idx_nm_angerErr)\n","df1\n","\n","# 칼럼 위치 변경\n","df1 = df1[[ \"sentiment\" ,\"text\"]]\n","\n","df1"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>joy</td>\n","      <td>오예 오늘 휴강이다!!!</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>love</td>\n","      <td>사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sadness</td>\n","      <td>오늘 감기에 걸렸다..</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>joy</td>\n","      <td>놀이공원 놀러왔다 신난다! &gt;_&lt;</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sadness</td>\n","      <td>아 외롭다..ㅜ</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1360</th>\n","      <td>anger</td>\n","      <td>ㅡㅡ 왜자꾸 카톡해</td>\n","    </tr>\n","    <tr>\n","      <th>1361</th>\n","      <td>sadness</td>\n","      <td>휴.....</td>\n","    </tr>\n","    <tr>\n","      <th>1362</th>\n","      <td>joy</td>\n","      <td>이것도 되나욬ㅋㅋㅋㅋㅋ</td>\n","    </tr>\n","    <tr>\n","      <th>1363</th>\n","      <td>surprise</td>\n","      <td>헉 정말요? .....뭔가 그사람들은 이번엔 뭘낼까 고민하는것도 일이겠어요... 아...</td>\n","    </tr>\n","    <tr>\n","      <th>1365</th>\n","      <td>anger</td>\n","      <td>제발 형섭이가 쓴 포스트잇 다시 가져다 놓으세요 정말루 ...... 진짜 더이상 짜...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1218 rows × 2 columns</p>\n","</div>"],"text/plain":["     sentiment                                               text\n","0          joy                                      오예 오늘 휴강이다!!!\n","1         love                        사랑한다. 이 세상 하나뿐인 내 아내와 아들, 딸\n","2      sadness                                       오늘 감기에 걸렸다..\n","3          joy                                 놀이공원 놀러왔다 신난다! >_<\n","4      sadness                                           아 외롭다..ㅜ\n","...        ...                                                ...\n","1360     anger                                         ㅡㅡ 왜자꾸 카톡해\n","1361   sadness                                             휴.....\n","1362       joy                                       이것도 되나욬ㅋㅋㅋㅋㅋ\n","1363  surprise  헉 정말요? .....뭔가 그사람들은 이번엔 뭘낼까 고민하는것도 일이겠어요... 아...\n","1365     anger  제발 형섭이가 쓴 포스트잇 다시 가져다 놓으세요 정말루 ...... 진짜 더이상 짜...\n","\n","[1218 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOmWAUomMoJP","executionInfo":{"status":"ok","timestamp":1621264536646,"user_tz":-540,"elapsed":789,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"930d7d4f-42a9-47b4-d98d-405ce011a35e"},"source":["df1.sentiment.unique()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['joy', 'love', 'sadness', 'anger', 'surprise', 'fear'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGKCpx1RLGfD","executionInfo":{"status":"ok","timestamp":1621264536948,"user_tz":-540,"elapsed":849,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"ea244858-73cf-4f01-cfda-05448ff9dd61"},"source":["df1.sentiment.value_counts()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["joy         588\n","sadness     293\n","anger       154\n","surprise    110\n","love         53\n","fear         20\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"0L0Zwy4o2uiI","executionInfo":{"status":"ok","timestamp":1621264536950,"user_tz":-540,"elapsed":599,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"15ab3882-c37b-4227-ab04-3d9b004451a5"},"source":["df2 = pd.read_csv(\"/content/drive/My Drive/캡스톤디자인/감정분류_데이터셋_최종.csv\", sep=\",\", header=None,encoding=\"cp949\")\n","\n","# 칼럼 이름 변경\n","df2.columns = [\"sentiment\",\"text\"]\n","\n","# 칼럼 위치 변경\n","# df2 = df2[[\"text\", \"sentiment]]\n"," \n"," # None 값 제거\n","df2 = df2.dropna()\n","\n","# 0번째 인덱스 삭제\n","df2 = df2.drop(df2.index[0])\n","\n","df2"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>anger</td>\n","      <td>100만 한번이면 말 다했지. 3.1운동도 100만이다. 몇번을 해야하나</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>surprise</td>\n","      <td>1시간 때울겸 회원가입하고 겜하다 20분하고 웹써핑한 기억이 납니다...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>surprise</td>\n","      <td>1천만명이란다ㅋㅋ전부 10배이상 뻥튀기 숫자를 그대로인정한거네 역시sbs</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>surprise</td>\n","      <td>500일 기념하던 때가 엊그제 같은데 시간 진짜 빨리 가는 것 같아요ㅠㅠ</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>surprise</td>\n","      <td>se가 일본과 유럽서는 호평이 자자한데어째서 한국서는 저리 비판 받는거지</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2654</th>\n","      <td>joy</td>\n","      <td>메시는 그닥 노잼일거같고... 그냥 섭외한다면 섭외능력에 감탄할뿐 솔직히 재미는 없...</td>\n","    </tr>\n","    <tr>\n","      <th>2655</th>\n","      <td>fear</td>\n","      <td>우주의 미세먼지의 미세먼지만도 못 한 크기의 지구에서 사는 인간이 우주의 먼지만도 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2656</th>\n","      <td>anger</td>\n","      <td>대구 비오고 있다 이 구라청 개 호 루 쉬키들아 주둥아리를 아작 내고 싶다 개상청 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2657</th>\n","      <td>anger</td>\n","      <td>일단 폭스바겐 사태를 떠나서 뒤에서 쥐샛끼 짓거리하는놈이 있는것같다. 난 흉다이가 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2658</th>\n","      <td>anger</td>\n","      <td>아니 원래 사드는 비밀리에 배치하고 배치한후에 발표하면 됐을것을 좌파들이 사드배치가...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2658 rows × 2 columns</p>\n","</div>"],"text/plain":["     sentiment                                               text\n","1        anger           100만 한번이면 말 다했지. 3.1운동도 100만이다. 몇번을 해야하나\n","2     surprise           1시간 때울겸 회원가입하고 겜하다 20분하고 웹써핑한 기억이 납니다...\n","3     surprise           1천만명이란다ㅋㅋ전부 10배이상 뻥튀기 숫자를 그대로인정한거네 역시sbs\n","4     surprise           500일 기념하던 때가 엊그제 같은데 시간 진짜 빨리 가는 것 같아요ㅠㅠ\n","5     surprise           se가 일본과 유럽서는 호평이 자자한데어째서 한국서는 저리 비판 받는거지\n","...        ...                                                ...\n","2654       joy  메시는 그닥 노잼일거같고... 그냥 섭외한다면 섭외능력에 감탄할뿐 솔직히 재미는 없...\n","2655      fear  우주의 미세먼지의 미세먼지만도 못 한 크기의 지구에서 사는 인간이 우주의 먼지만도 ...\n","2656     anger  대구 비오고 있다 이 구라청 개 호 루 쉬키들아 주둥아리를 아작 내고 싶다 개상청 ...\n","2657     anger  일단 폭스바겐 사태를 떠나서 뒤에서 쥐샛끼 짓거리하는놈이 있는것같다. 난 흉다이가 ...\n","2658     anger  아니 원래 사드는 비밀리에 배치하고 배치한후에 발표하면 됐을것을 좌파들이 사드배치가...\n","\n","[2658 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aQoo91HRVhs","executionInfo":{"status":"ok","timestamp":1621264537727,"user_tz":-540,"elapsed":1147,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"fcd1d2bd-b6a9-437d-c616-63c0aa17edcf"},"source":["# df2.sentiment.unique()\n","df2.sentiment.value_counts()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["anger       643\n","joy         570\n","fear        532\n","sadness     526\n","surprise    387\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"3VtygsFyrk0N","executionInfo":{"status":"ok","timestamp":1621264537728,"user_tz":-540,"elapsed":900,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"4670b830-6aa8-4233-c70f-377a17b5fecb"},"source":["# tag_live 크롤링.\n","df3 = pd.read_csv(\"/content/drive/MyDrive/캡스톤디자인/tag_live.csv\")\n","df3 = df3[[\"text\", \"keyword\"]]\n","df3.columns = [\"text\", \"sentiment\"]\n","df3 = df3[[\"sentiment\", \"text\"]]\n","\n","# 'neutral' 행 제거\n","idx_nm_neutral= df3[df3['sentiment'] == 'neutral'].index\n","df3 = df3.drop(idx_nm_neutral)\n","\n","\n","df3[:10]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>anger</td>\n","      <td>늘 즐겁고 재밌는 유익한 시간이 되세요 - 우리집 고양이 화났음이건 고양인지 호랑이...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>anger</td>\n","      <td>&lt;article author_link=\"//instagram.com/p/CFN9vh...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>anger</td>\n","      <td>&lt;article author_link=\"//instagram.com/p/CFN6RO...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>anger</td>\n","      <td>#자기#똥서유니라고#놀렷다그#화났음 #아진~짜이상하네#세살의반란#자기#똥서유니라고#...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>anger</td>\n","      <td>&lt;article author_link=\"//instagram.com/p/CFKSm5...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>anger</td>\n","      <td>#화났음#인상파#코에 상처# 잠깐 한눈 판 사이에 긁어놓음#상처엔 마데카솔?#화났음...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>anger</td>\n","      <td>&lt;article author_link=\"//instagram.com/p/CFAADW...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>anger</td>\n","      <td>#화났음#사진#제발이뿌게좀..#발이야발#ㅋㅋ#오늘도맑음#하늘도맑음#오늘의운동화#컨버...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>anger</td>\n","      <td>거울만 보면 힘 주기 바쁨🏋🏻‍♂️#헬창남치...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>anger</td>\n","      <td>&lt;article author_link=\"//instagram.com/p/CEy1Jx...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sentiment                                               text\n","0     anger  늘 즐겁고 재밌는 유익한 시간이 되세요 - 우리집 고양이 화났음이건 고양인지 호랑이...\n","1     anger  <article author_link=\"//instagram.com/p/CFN9vh...\n","2     anger  <article author_link=\"//instagram.com/p/CFN6RO...\n","3     anger  #자기#똥서유니라고#놀렷다그#화났음 #아진~짜이상하네#세살의반란#자기#똥서유니라고#...\n","4     anger  <article author_link=\"//instagram.com/p/CFKSm5...\n","5     anger  #화났음#인상파#코에 상처# 잠깐 한눈 판 사이에 긁어놓음#상처엔 마데카솔?#화났음...\n","6     anger  <article author_link=\"//instagram.com/p/CFAADW...\n","7     anger  #화났음#사진#제발이뿌게좀..#발이야발#ㅋㅋ#오늘도맑음#하늘도맑음#오늘의운동화#컨버...\n","8     anger  거울만 보면 힘 주기 바쁨🏋🏻‍♂️#헬창남치...\n","9     anger  <article author_link=\"//instagram.com/p/CEy1Jx..."]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvvPkOKLsevG","executionInfo":{"status":"ok","timestamp":1621264538051,"user_tz":-540,"elapsed":663,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"14cf7eb4-38a0-4a33-e406-95c7ee725cf8"},"source":["df3.sentiment.unique()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"976Hq1vstjEa","executionInfo":{"status":"ok","timestamp":1621264538294,"user_tz":-540,"elapsed":624,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"b15057b4-1fd4-4694-d6be-5d690e89c629"},"source":["df3.sentiment.value_counts()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sadness     377\n","anger       178\n","joy         142\n","fear        123\n","surprise    107\n","love         82\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"-KAMc6Xi6MvW"},"source":["#데이터 프레임 합치기"]},{"cell_type":"code","metadata":{"id":"laC0FHmlto_z","executionInfo":{"status":"ok","timestamp":1621264540262,"user_tz":-540,"elapsed":955,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["# df 에 df1, df2, df3 데이터프레임 합치기.\n","df = df.append(df1)\n","df = df.append(df2)\n","df = df.append(df3)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFX9D_qs9MOg","executionInfo":{"status":"ok","timestamp":1621264541050,"user_tz":-540,"elapsed":595,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["# 데이터 프레임 셔플\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KI1lBggdVh9x","executionInfo":{"status":"ok","timestamp":1621264542620,"user_tz":-540,"elapsed":1421,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"c83d71dd-96b3-4db2-ab35-e5831fc0567f"},"source":["# df.sentiment.unique()\n","df.sentiment.value_counts()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["joy         1491\n","sadness     1388\n","anger       1072\n","fear         731\n","surprise     661\n","love         201\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"wuaa_owH9uik"},"source":["\n","# 전처리 해봐야 할것\n","- 문장에 url 주소들이 많은 것들.\n","- 반복되는 문장"]},{"cell_type":"code","metadata":{"id":"lShnhgFv2uc9","executionInfo":{"status":"ok","timestamp":1621264545235,"user_tz":-540,"elapsed":605,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["def clean_str(text):\n","    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n","    text = re.sub(pattern=pattern, repl=' ', string=text)\n","    # pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n","    pattern = 'https?://(\\w*:\\w*@)?[-\\w.]+(:\\d+)?(/([\\w/_.]*(\\?\\S+)?)?)?' # URL제거\n","    # pattern = '/^(file|gopher|news|nntp|telnet|https?|ftps?|sftp):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/' # URL제거\n","    text = re.sub(pattern=pattern, repl=' ', string=text)\n","    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n","    text = re.sub(pattern=pattern, repl=' ', string=text)\n","    pattern = '<[^>]*>'         # HTML 태그 제거\n","    text = re.sub(pattern=pattern, repl=' ', string=text)\n","    pattern = '[^\\w\\s]'         # 특수기호제거\n","    text = re.sub(pattern=pattern, repl='', string=text)\n","    pattern = '(amp)|(gt)|(lt)|_|[0-9]'         # amp 제거\n","    text = re.sub(pattern=pattern, repl=' ', string=text)\n","    return text"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXwxAZsj2uac","executionInfo":{"status":"ok","timestamp":1621264546686,"user_tz":-540,"elapsed":1177,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["# 전처리 실행\n","df[\"text\"] = df[\"text\"].apply(lambda x: clean_str(x))"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDZ_dCoE2uXy","executionInfo":{"status":"ok","timestamp":1621264547331,"user_tz":-540,"elapsed":548,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"9d1f44a8-9624-4c01-c840-9e04b2737165"},"source":["df.shape"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5544, 2)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"VU9i4Ddr9-Re"},"source":["# (조건부 확인) BERT 모델에 맞게 데이터 변환\n","\n","- 문자열의 길이를 세서 100글자 이내라면 삭제\n"]},{"cell_type":"code","metadata":{"id":"HkXqQafq2uUq","executionInfo":{"status":"ok","timestamp":1621264553446,"user_tz":-540,"elapsed":4107,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["# 문자열의 길이를 세서 100글자 이내라면 삭제\n","sum=0\n","\n","change_csv= pd.DataFrame(columns=['text', \"sentiment\"])\n","\n","for i in range(len(df['text'])):\n","  if(len(df['text'][i])>=100): #길이가 100이상이면\n","    change_csv.loc[sum]=df.loc[i]\n","    sum+=1\n","# print(change_csv)\n","\n","# csv 저장\n","change_csv.to_csv('/content/drive/My Drive/캡스톤디자인/최종전처리_데이터셋.csv')"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSaXjQqz2uR0","executionInfo":{"status":"ok","timestamp":1621264602222,"user_tz":-540,"elapsed":586,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}}},"source":["df = pd.read_csv(\"/content/drive/My Drive/캡스톤디자인/최종전처리_데이터셋.csv\",index_col = 0)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"abiyT-SKSE_N","executionInfo":{"status":"ok","timestamp":1621264605812,"user_tz":-540,"elapsed":1084,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"687f3bc4-0802-43e3-bdfa-5c238f0d7f03"},"source":["df.sentiment.value_counts()"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sadness     510\n","joy         324\n","anger       272\n","fear        150\n","love        125\n","surprise    115\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"nTojBL6q2uPK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621264608104,"user_tz":-540,"elapsed":641,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"fa96e198-0f70-4b86-ae08-4b4a319f22e1"},"source":["df.shape"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1496, 2)"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bxx1bwl1fKoY","executionInfo":{"status":"ok","timestamp":1621264610078,"user_tz":-540,"elapsed":830,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"3e4e4ff4-728b-4120-dde1-fb5a93478c53"},"source":["df.info()"],"execution_count":54,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 1496 entries, 0 to 1495\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   text       1496 non-null   object\n"," 1   sentiment  1496 non-null   object\n","dtypes: object(2)\n","memory usage: 35.1+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAlSvRD72uMi","executionInfo":{"status":"ok","timestamp":1621257664957,"user_tz":-540,"elapsed":1094,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"db257415-4075-47ce-856d-6b6a3b052b62"},"source":["# df= df.drop(['Unnamed: 0'], axis=1)\n","# df.info()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1496 entries, 0 to 1495\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   text       1496 non-null   object\n"," 1   sentiment  1496 non-null   object\n","dtypes: object(2)\n","memory usage: 23.5+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hK9HXgqaxWE","executionInfo":{"status":"ok","timestamp":1621257204044,"user_tz":-540,"elapsed":935,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"92b8cf73-ae0e-4b55-8ccf-920019b0e171"},"source":["# df.sentiment.value_counts()"],"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sadness     510\n","joy         324\n","anger       272\n","fear        150\n","love        125\n","surprise    115\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":111}]},{"cell_type":"markdown","metadata":{"id":"NJrjhxft_Egd"},"source":["#훈련셋 테스트셋 split"]},{"cell_type":"code","metadata":{"id":"C_-pBAFm2uHD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958000,"user_tz":-540,"elapsed":6003,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"e3334667-3c54-4d89-a4e7-62cd645c7e9a"},"source":["# text\n","text = df[\"text\"][:-300]\n","# BERT의 입력 형식에 맞게 변환\n","text = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in text]\n","text[:10]\n","len(text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1196"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"markdown","metadata":{"id":"EKn2xYkT_NAq"},"source":["#문장길이 확인 (사용 X)"]},{"cell_type":"code","metadata":{"id":"vnpg420S2uEO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958001,"user_tz":-540,"elapsed":5993,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"04c201eb-58c0-4bd0-d7a1-d321a5c24ee3"},"source":["\n","# text\n","test_text = df[\"text\"][:-600]\n","test_text"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      키토제닉 다이어트 식단 너무어렵다 저탄고지 도시락 실패함키토제닉 다이어트 식단 너무...\n","1      아기가 생기면 해줘야지 하는게 몇개 있다 그중 하나가 이런날 선물 챙겨주기 다른건 ...\n","2      왜 기상캐스터 보는맛에 뉴스보는데  코디도 나름 잘 신경써서 나오고 앵커들 얼굴만보...\n","3      상속포기 기간과 절차를 반드시 확인하세요오늘은 고윤기 변호사의 칼럼 상속포기에도 때...\n","4      그래 난 누군가에겐 봄 누군가에게는 겨울 누군가에겐 끝 누군가에게는 처음 난 누군가...\n","                             ...                        \n","891    오늘 온라인 미팅 중에 많이 울었다 슬프거나힘들어서 운 것은 아니다 내가 살아있는 ...\n","892    어쩌다육아 모성애 따위는 개나 줘버려  생후   일모성애의 뜻을 살펴보면 자식에 대...\n","893    이 날 엠아롱 솔직히 즴읹이 다 해먹은 날 정귻이 뒤에서 시무룩한 표정하고 씨익 웃...\n","894    기회가 온다면 고민하지 말고 그 기회를 잡으시길 바래요 그 기회가 자신이 바라고 바...\n","895     오늘 진짜 정신 도없었는데결국 티켓팅 폭망 나 못보면신나는곳 한복판에서대성통곡 할...\n","Name: text, Length: 896, dtype: object"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"_0bQTxCJ2uBy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958002,"user_tz":-540,"elapsed":5981,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"020e9bf0-7aef-4cca-a46d-5097f5919285"},"source":["test_text[2500:2525]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], Name: text, dtype: object)"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"gKJFLuUe2t_L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958003,"user_tz":-540,"elapsed":5971,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"1dbd662c-6705-4657-b8ac-d900f8b70b6f"},"source":["# for 문 진행 상황 볼 수 있는 라이브러리\n","from tqdm import tqdm\n","\n","\n","ntext = []\n","\n","for sentence in tqdm(test_text):\n","  # token = []\n","  words = sentence.split()\n","\n","  ntext.append(words)\n","  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 896/896 [00:00<00:00, 116180.68it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dGwXT4Zm2t8o","colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"status":"ok","timestamp":1620331958004,"user_tz":-540,"elapsed":5959,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"66ec0873-cc8e-4d7d-c1e4-6db92ca0c406"},"source":["import matplotlib.pyplot as plt\n","\n","len_text = []\n","for data in ntext:\n","    len_text.append(len(data))\n","\n","plt.hist(len_text, label='text', alpha=0.7)\n","\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"r0wavTOyYDhr"},"source":["# Label to Integer"]},{"cell_type":"code","metadata":{"id":"Wlwbk0y22t6P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958004,"user_tz":-540,"elapsed":5944,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"90f131a6-8624-42b3-c8a5-d4f74b72f2d7"},"source":["# label이 문자이므로 숫자값으로 바꿔줘야함 - LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","\n","sentiment = label_encoder.fit_transform(df[\"sentiment\"][:-300])\n","\n","\n","# sentiment = sentiment.reshape(-1,1)\n","sentiment.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1196,)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"tfcvolAn2t3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331958005,"user_tz":-540,"elapsed":5933,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"cb115297-fb08-4ba5-dd45-f42d7efef724"},"source":["label_encoder.classes_\n","# label_encoder.inverse_transform(sentiment)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"xs6SMfxR2t0s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331960622,"user_tz":-540,"elapsed":8539,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"20160fa0-10be-430b-cc16-3ae0fa800300"},"source":["# 트랜스 포머 설치\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IRGeo1bI2tx_"},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFEmyoSN2tvY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962216,"user_tz":-540,"elapsed":10114,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"a7315e44-fb47-476f-86d4-24e3823f47b9"},"source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in text]\n","\n","print (text[0])\n","print (tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] 키토제닉 다이어트 식단 너무어렵다 저탄고지 도시락 실패함키토제닉 다이어트 식단 너무어렵다 저탄고지 도시락 실패함  어후  직장 생활을 오래하면 오래할수록 미친듯이 살이 찌기 시작하더라구요     윤블리의 뷰티다이어리 일 전  키토제닉 다이어트 식단 너무어렵다 저탄고지 도시락 실패함키토제닉 다이어트 식단 너무어렵다 저탄고지 도시락 실패함  어후  직장 생활을 오래하면 오래할수록 미친듯이 살이 찌기 시작하더라구요      [SEP]\n","['[CLS]', '키', '##토', '##제', '##닉', '다', '##이어', '##트', '식', '##단', '너', '##무', '##어', '##렵', '##다', '저', '##탄', '##고', '##지', '도시', '##락', '실', '##패', '##함', '##키', '##토', '##제', '##닉', '다', '##이어', '##트', '식', '##단', '너', '##무', '##어', '##렵', '##다', '저', '##탄', '##고', '##지', '도시', '##락', '실', '##패', '##함', '어', '##후', '직', '##장', '생', '##활', '##을', '오', '##래', '##하면', '오', '##래', '##할', '##수', '##록', '미', '##친', '##듯', '##이', '살', '##이', '찌', '##기', '시', '##작', '##하', '##더', '##라', '##구', '##요', '윤', '##블', '##리의', '뷰', '##티', '##다', '##이어', '##리', '일', '전', '키', '##토', '##제', '##닉', '다', '##이어', '##트', '식', '##단', '너', '##무', '##어', '##렵', '##다', '저', '##탄', '##고', '##지', '도시', '##락', '실', '##패', '##함', '##키', '##토', '##제', '##닉', '다', '##이어', '##트', '식', '##단', '너', '##무', '##어', '##렵', '##다', '저', '##탄', '##고', '##지', '도시', '##락', '실', '##패', '##함', '어', '##후', '직', '##장', '생', '##활', '##을', '오', '##래', '##하면', '오', '##래', '##할', '##수', '##록', '미', '##친', '##듯', '##이', '살', '##이', '찌', '##기', '시', '##작', '##하', '##더', '##라', '##구', '##요', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5EBmmNlJ2ttK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962217,"user_tz":-540,"elapsed":10103,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"eb5f07fb-5a9e-420f-9bea-915c395efeb3"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 256\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9838,  26444,  17730, 118766,   9056,  86732,  15184,\n","         9486,  24989,   9004,  32537,  12965, 118879,  11903,   9663,\n","        66554,  11664,  12508, 101660, 107693,   9489, 119383,  48533,\n","        21039,  26444,  17730, 118766,   9056,  86732,  15184,   9486,\n","        24989,   9004,  32537,  12965, 118879,  11903,   9663,  66554,\n","        11664,  12508, 101660, 107693,   9489, 119383,  48533,   9546,\n","        31531,   9707,  13890,   9420, 119446,  10622,   9580,  37388,\n","        38378,   9580,  37388,  14843,  15891,  31398,   9309,  55358,\n","       118817,  10739,   9408,  10739,   9727,  12310,   9485,  38709,\n","        35506,  54141,  17342,  17196,  48549,   9627,  92564,  50053,\n","         9375,  45725,  11903,  86732,  12692,   9641,   9665,   9838,\n","        26444,  17730, 118766,   9056,  86732,  15184,   9486,  24989,\n","         9004,  32537,  12965, 118879,  11903,   9663,  66554,  11664,\n","        12508, 101660, 107693,   9489, 119383,  48533,  21039,  26444,\n","        17730, 118766,   9056,  86732,  15184,   9486,  24989,   9004,\n","        32537,  12965, 118879,  11903,   9663,  66554,  11664,  12508,\n","       101660, 107693,   9489, 119383,  48533,   9546,  31531,   9707,\n","        13890,   9420, 119446,  10622,   9580,  37388,  38378,   9580,\n","        37388,  14843,  15891,  31398,   9309,  55358, 118817,  10739,\n","         9408,  10739,   9727,  12310,   9485,  38709,  35506,  54141,\n","        17342,  17196,  48549,    102,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"5oUvyqz42tqo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962807,"user_tz":-540,"elapsed":10682,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"5c8bfe52-d1aa-478a-852f-e3c6e743c0cb"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8rKyqbOl2tn4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962808,"user_tz":-540,"elapsed":10671,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"fe21f47f-d4ff-4b58-ddb2-d45fd1de0345"},"source":["# 훈련셋과 검증셋으로 분리\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                    sentiment, \n","                                                                                    random_state=2020, \n","                                                                                    test_size=0.2)\n","\n","# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=2020, \n","                                                       test_size=0.2)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\t\t\t\t\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])\n","\n","train_inputs.shape, train_labels.shape, train_masks.shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([   101,   9812,   9521,  10530,   9638, 118624,   9010,  11664,   9519,\n","         28396,  85634,   9954, 118624,   9524,  11664,    100,   9150,  11664,\n","          9365,  31401,  59894,   8984,  12692,  18622,  11903,   9812,   9912,\n","          9937, 119138,  54141,  25503,    100,  32487,   9886,  12965,  16439,\n","        119156,   9025,  49919,  23811,  32158,   9708,  16605,   9485,  66815,\n","        102246,   9993,  12092,   8982,  11664,   9666,  14423,   9521,  22096,\n","         11018, 118624,   9524,  26737, 119219,   9735,  10530,   9357,  21155,\n","         20309, 119465,  11467,   9638,  49543,   9365,  31401,  25503,   9663,\n","         12692,   9464,  17706,   9663,  14153,   9464,  10892,  41521,  37388,\n","         22458, 119265,   9952,   9004,  32537,   8920,  29935,  69592,  12424,\n","          9609,  11018,   9318,  61250,  10530,  10015,  12508,  52015,  12508,\n","          9708, 119235,   9018, 105197,  15891,    102,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])\n","tensor(5)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n","tensor([   101,   9095,  24017, 106826, 119412,   9641,   9638, 118979,  15184,\n","         18471,  29364,  16985, 119285,  10530,   8929,  17594,  19105,  93200,\n","         12424,  54141,   9576, 119023, 118691,  10892,   9290,  14523, 119222,\n","         28578,  10739,  41521, 118965,  11664,   8848,  18778, 118965,  16985,\n","          9607, 119138, 118775,  48446,  11903, 119408, 119408,  12453,   9494,\n","         78136,  30873,  21614,   9004,  49515,  11513,   9044,   9636,  14279,\n","         14843, 118683, 119326, 118751,  16439,  12945,  62200,   9095,  24017,\n","         12945,  62200,    100,   9595, 119019, 118817,   8857, 119019, 118817,\n","         18392,  14871, 101472,   9766,  35506,  14523,   9405,  62200,  14523,\n","          8920,  48549,  22458,  27023,   9095,  24017, 106826, 119412,   9641,\n","          9638, 118979,  15184,  18471,  29364,  16985,   9485,  18784,   9665,\n","          9095,  24017, 106826, 119412,   9641,   9638, 118979,  15184,  18471,\n","         29364,  16985, 119285,  10530,   8929,  17594,  19105,  93200,  12424,\n","         54141,   9576, 119023, 118691,  10892,   9290,  14523, 119222,  28578,\n","         10739,  41521, 118965,  11664,   8848,  18778, 118965,  16985,   9607,\n","        119138, 118775,  48446,  11903, 119408, 119408,  12453,   9494,  78136,\n","         30873,  21614,   9004,  49515,  11513,   9044,   9636,  14279,  14843,\n","        118683, 119326, 118751,  16439,  12945,  62200,   9095,  24017,  12945,\n","         62200,    100,   9595, 119019, 118817,   8857, 119019, 118817,  18392,\n","         14871, 101472,   9766,  35506,  14523,   9405,  62200,  14523,   8920,\n","         48549,  22458,  27023,    102,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])\n","tensor(2)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([956, 256]), torch.Size([956]), torch.Size([956, 256]))"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"UMGpSOZf2tk6"},"source":["# 배치 사이즈\n","batch_size = 16\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzpS9kZ52tcY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962809,"user_tz":-540,"elapsed":10653,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"41b324b8-4344-4260-ec72-c471d904f157"},"source":["# 테스트 셋\n","test_sentences = df[\"text\"][-300:]\n","test_sentences"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1196     피말리는   일 일연속 응급실행 하다가  박 일 입원하고 퇴원 자가격리시키고 오늘...\n","1197    오늘의 레슨   체중이동  임팩  피니쉬  머...\n","1198    아닌 척 애써 감추는 눈물 애써 감추는 감정 애써 억누르는 슬픔 애써 아닌 척 밝게...\n","1199    자전고운동 아무나하는거아니다  루 뼈해장국 잘먹었...\n","1200    유아식 어렵다 간단하게   개월아들 아기먹방 건강하게 튼실하게 해피베이비 아들스타그...\n","                              ...                        \n","1491    마침내 세월호를 육지로 끌어올린 힘도 무력감과 죄의식의 연대들이 만들어낸 분노가 근...\n","1492    중고피아노매입 어려움이 없어요하지만 가족 모두가 힘을 동원해도 피아노를 처분하는 것...\n","1493     영어나들이  교시열심히 함께한 키트교원이기에 가능한가오늘밤은 엄마도 어려워하는악기...\n","1494     부정적인 말을 하지말라길래가까이서 보ᄌ...\n","1495     키즈박스떡퐁당오뎅퐁당계란퐁당파숑...\n","Name: text, Length: 300, dtype: object"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"id":"kPhbVPSk2tZu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620331962810,"user_tz":-540,"elapsed":10642,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"b670e337-7329-4bef-95b6-ef5a4b277084"},"source":["# BERT의 입력 형식에 맞게 변환\n","test_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in test_sentences]\n","test_sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]  피말리는   일 일연속 응급실행 하다가  박 일 입원하고 퇴원 자가격리시키고 오늘 피검사결과 모든수치 다 정상돌아옴 정말 지옥까지 내려갔다가 하이파이브하고 올라온 느낌제발 건강만하자 이쁜연지공주야  개월아기돌발진호중구감소백혈구감소피말린다매일채혈돌아버리는줄건강만하자사랑해딸 피말리는   일 일연속 응급실행 년 전    피말리는   일 일연속 응급실행 하다가  박 일 입원하고 퇴원 자가격리시키고 오늘 피검사결과 모든수치 다 정상돌아옴 정말 지옥까지 내려갔다가 하이파이브하고 올라온 느낌제발 건강만하자 이쁜연지공주야  개월아기 돌발진 호중구감소 백혈구감소 피말린다 매일채혈 돌아버리는줄 건강만하자 사랑해딸  [SEP]',\n"," '[CLS] 오늘의 레슨   체중이동  임팩  피니쉬  머리고정잘치고싶다 잘치고싶다 멀리보내고 싶다골프 golf 유틸리티샷 golfswing 골프스윙 라운딩준비 운동하는여자 골린이 연습만이살길 하나를치더라도제대로 많이친다고잘칠거같으면벌써만개침 어렵다  번유틸    기록남기기오늘의 레슨   시간 전   오늘의 레슨   체중이동  임팩  피니쉬  머리고정잘치고싶다 잘치고싶다 멀리보내고 싶다골프 golf 유틸리티샷 golfswing 골프스윙 라운딩준비 운동하는여자 골린이 연습만이살길 하나를치더라도제대로 많이친다고잘칠거같으면벌써만개침 어렵다  번유틸    기록남기기  [SEP]',\n"," '[CLS] 아닌 척 애써 감추는 눈물 애써 감추는 감정 애써 억누르는 슬픔 애써 아닌 척 밝게 웃어본다 내 감정을 감춰본다 하지만 숨길 수 없는 내 감정 표정 슬픔 입은 웃고 있지만 눈에는 눈물이 흐른다 말은 괜찮다 별일없다 라는 뻔한 거짓말 넌 잘 알고 있잖아 별일 있고 힘들어 하고 무너져 내려가는데 견딜 수 없는데 그렇게 웃으면서 아무렇지 않게 얘기한다 힘들어 하면서 마음이 아프면서 그렇게 나는 가면 속에서 살아간다   힘들면 힘들다고 표현해도 돼 울고 싶으면 울어도 돼 굳이 네가 힘들게 혼자 끙끙거리지 말고 다른 사람한테 표현을 해봐 겁 먹지 말고 천천히 [SEP]',\n"," '[CLS] 자전고운동 아무나하는거아니다  루 뼈해장국 잘먹었습니다감사합니당자전거라이딩 자전거타기  한강 한강자전거타기 운동 개힘듬 사람이할짓이아님   어우야 엉덩이근육 작살남  못앉음주의자전고운동 아무나 일 전   자전고운동 아무나하는거아니다  루 뼈해장국 잘먹었습니다감사합니당자전거라이딩 자전거타기  한강 한강자전거타기 운동 개힘듬 사람이할짓이아님   어우야 엉덩이근육 작살남  못앉음주의  [SEP]',\n"," '[CLS] 유아식 어렵다 간단하게   개월아들 아기먹방 건강하게 튼실하게 해피베이비 아들스타그램 이뻐이뻐요 homemadebabyfood toddlerlife babymukbang   monthsold  koreanbaby oclife mynewlifeasamom homemadekoreanbabyfood입맛 상승 아들램요 몇일 또 다시 먹방을 찍는 아들때문에 밥할맛이 나는구먼원래는 아침에 야채스크램블만 주구장창 먹었지만 한번 메뉴 바꿔야겠다 생각하고 이유식때 제일 좋아했던 미역죽을 간을 해서 주니 엄청나게 잘 먹었다는 어제는  개월 만에 처음으로준이는 살면서 처름으로 고깃집을 갔는데 미니고기 메뉴가 있어서 준이 시켜줬더니끝장을내고 오셨어요 안창살 일인분 좀 덜되는 고기  계란찜  콘치즈  밥  김치 부침개 아주 조금 맛만보라고   동치미 국물까지 아주 알차게 잘 먹었어요   엄마가 워낙 매운걸 좋아해서 김치를 한번 줬더니 아주 잘 먹었던 강준그래도 김치는 소금이 너무 많으니까 나중에 먹는걸로 오늘은 점심 끝나고 갑자기 냉장고를 가르키며 파파파 하길래 의자에서 내려주니 냉장고를 열고 파인애플  을 가지고 나온 아들램 밥 다 먹었으니 준이 최애 과일 달라고 하는거였다니울 아들 다 컸네이번주도 이렇게 엄마 쉬는날을 맛있게 먹고 알차게 보냅니다  닭고기 고기는 아빠가 구워줘야 제맛 남편이 말하길 기름두르고 한쪽을 쭉 익힌다음에 중간넘께 익으면 그때 뒤집어서 익혀야 한답니다 중불 온리  버섯양파   버섯  호박 닭고기 굽고 바로 구우면 더 맛있음  미역죽 소고기 미역 표고  간장조금  다진마늘 물 밥  파인애플 I유아식 어렵다 간단하게   개 시간 전  유아식 어렵다 간단하게   개월아들 아기먹방 건강하게 튼실하게 해피베이비 아들스타그램 이뻐이뻐요 homemadebabyfood toddlerlife babymukbang   monthsold koreanbaby oclife mynewlifeasamom homemadekoreanbabyfood 입맛 상승 아들램요 몇일 또 다시 먹방을 찍는 아들때문에 밥할맛이 나는구먼원래는 아침에 야채스크램블만 주구장창 먹었지만 한번 메뉴 바꿔야겠다 생각하고 이유식때 제일 좋아했던 미역죽을 간을 해서 주니 엄청나게 잘 먹었다는 어제는  개월 만에 처음으로준이는 살면서 처름으로 고깃집을 갔는데 미니고기 메뉴가 있어서 준이 시켜줬더니끝장을내고 오셨어요 안창살 일인분 좀 덜되는 고기  계란찜  콘치즈  밥  김치 부침개 아주 조금 맛만보라고   동치미 국물까지 아주 알차게 잘 먹었어요   엄마가 워낙 매운걸 좋아해서 김치를 한번 줬더니 아주 잘 먹었던 강준그래도 김치는 소금이 너무 많으니까 나중에 먹는걸로 오늘은 점심 끝나고 갑자기 냉장고를 가르키며 파파파 하길래 의자에서 내려주니 냉장고를 열고 파인애플  을 가지고 나온 아들램 밥 다 먹었으니 준이 최애 과일 달라고 하는거였다니울 아들 다 컸네이번주도 이렇게 엄마 쉬는날을 맛있게 먹고 알차게 보냅니다  닭고기 고기는 아빠가 구워줘야 제맛 남편이 말하길 기름두르고 한쪽을 쭉 익힌다음에 중간넘께 익으면 그때 뒤집어서 익혀야 한답니다 중불 온리  버섯양파   버섯  호박 닭고기 굽고 바로 구우면 더 맛있음  미역죽 소고기 미역 표고  간장조금  다진마늘 물 밥  파인애플 I [SEP]',\n"," '[CLS] 아침부터 떼써서 데리고 나왔더니 또 마스크는 안쓴다고 집어던지고 마트가 집도 아닌데 신발은 왜자꾸 벗는지 TV보니까 서진이랑 비슷한 개월차 아가들 양고기 닭다리도 잘 뜯던데 서지니는 도대체 들고 뜯질 않음 오늘도 장봐와서 새로 만들어줬지만 결국 닭다리 두개 내가 다 먹어버렸음하아 유아식 어려움   개월아기 세살아기 육아 육아일기 일상 워킹맘 아들맘 육아일상 성장일기 개띠맘  育兒 コトモタカラ 生後  ヶ月 男の子ママ ほっちゃり 成長日記 いいね返し아침부터 떼써서 데  시간 전   아침부터  떼써서 데리고 나왔더니 또 마스크는 안쓴다고 집어던지고 마트가 집도 아닌데 신발은 왜자꾸 벗는지 TV보니까 서진이랑 비슷한 개월차 아가들 양고기 닭다리도 잘 뜯던데 서지니는 도대체 들고 뜯질 않음 오늘도 장봐와서 새로 만들어줬지만 결국 닭다리 두개 내가 다 먹어버렸음하아 유아식 어려움   개월아기 세살아기 육아 육아일기 일상 워킹맘 아들맘 육아일상 성장일기 개띠맘   育兒 コトモタカラ 生後  ヶ月 男の子ママ ほっちゃり 成長日記 いいね返し  [SEP]',\n"," '[CLS] 棒Live 웨이보 사진을 보고 수수께끼를 맞혀보세요     厨男的诱惑요리남의유혹의 밍왕의 신비한 쿠키영상에서 샤오밍학생과 샤오나이왕은 도대체 뭘 하고 있는 걸까요 쿠키영상을 기대해주세요  [SEP]',\n"," '[CLS] 코로나 너무싫다 증말학원마칠때까지 차에서 대기모드제발 마스크좀 쓰고 다니세요하지말라면 쫌 하지마세요우리아이들이 무슨죄냐구요  대구신천지끝나고 이제겨우 괜찮아졌는데보고싶은 사람도 맘편히 못만나고너무슬픔  예주는 얼집도못가고 집에서 바보되가는중이고 어른들의 이기심으로 힘들게 만들어서 미얀해 제발 나는 괜찮겠지하는 생각은 개나줘버려 화났음 이기적인사람들포기하지말아요 나하나부터 말좀들어요 제발 아이들을위해 조심또조심마스크안쓰는날이빨리오길 마스크안쓴사람은뭐냐코로나 너무싫다 증말  일 전   코로나 너무싫다 증말학원마칠때까지 차에서 대기모드제발 마스크좀 쓰고 다니세요하지말라면 쫌 하지마세요우리아이들이 무슨죄냐구요  대구신천지끝나고 이제겨우 괜찮아졌는데보고싶은 사람도 맘편히 못만나고너무슬픔  예주는 얼집도못가고 집에서 바보되가는중이고 어른들의 이기심으로 힘들게 만들어서 미얀해 제발 나는 괜찮겠지하는 생각은 개나줘버려 화났음 이기적인사람들포기하지말아요 나하나부터 말좀들어요 제발 아이들을위해 조심또조심마스크안쓰는날이빨리오길마스크안쓴사람은뭐냐  [SEP]',\n"," '[CLS] 사이에서 희게 피어오른 날이었다 맺음새 없이 매끈하지도 않았던 옅게 깔린 안개만큼이나 흐렸했다 감히 이야기를 청해 한 숨 돌릴 새도 없이 두드리는 연의 계 딱히 누군가가 있지 않을 사이 검은 하늘이라도 비춰주었으면 하였지만 어떤 잎도 붉지 못했다 아마도 이젠 다시는 그렇게 말들에 지쳐서 귀를 막는다 담그어도 더럽혀지지 않는 그저 흰 사람을 원했을 뿐인데 [SEP]',\n"," '[CLS] 슈퍼 울트라 짱짱 귀엽고 예쁘고 사랑스럽고 천사이신 우리 트친님 트친 된지 얼마 안된거 같은데 엄청 친해진것 같은 혼자만의 착각에 빠지게 해주셨어요  내적친밀감만 억단위 넘어갈듯해요 저랑 트친해주셔서 감사하구요 오래봤으면 좋겠어요 [SEP]']"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbuglgXBYhVV","executionInfo":{"status":"ok","timestamp":1620331962812,"user_tz":-540,"elapsed":10632,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"c69b6dcc-11f1-453e-c866-4776b79d4bad"},"source":["# label이 문자이므로 숫자값으로 바꿔줘야함 - LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","test_label_encoder = LabelEncoder()\n","\n","test_sentiment = test_label_encoder.fit_transform(df[\"sentiment\"][-300:])\n","\n","test_sentiment"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 4, 4, 5, 4, 4, 2, 0, 4, 2, 4, 2, 4, 0, 4, 4, 5, 2, 4, 2, 4, 2,\n","       4, 5, 2, 1, 0, 5, 4, 4, 4, 2, 0, 4, 2, 5, 1, 0, 4, 2, 4, 4, 5, 1,\n","       5, 4, 4, 4, 5, 2, 5, 1, 4, 2, 2, 0, 2, 0, 0, 3, 2, 2, 0, 5, 5, 0,\n","       4, 4, 4, 4, 1, 3, 1, 4, 0, 0, 3, 2, 0, 1, 3, 0, 4, 0, 2, 4, 1, 1,\n","       2, 4, 0, 2, 4, 0, 4, 0, 0, 2, 0, 4, 0, 1, 4, 3, 0, 0, 2, 4, 1, 3,\n","       0, 4, 4, 3, 4, 3, 4, 5, 1, 3, 2, 2, 1, 2, 3, 4, 4, 2, 4, 4, 2, 4,\n","       4, 0, 2, 3, 4, 2, 2, 4, 4, 2, 1, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4,\n","       3, 0, 2, 4, 4, 4, 2, 4, 2, 4, 0, 4, 4, 3, 4, 0, 4, 0, 0, 4, 0, 4,\n","       3, 4, 4, 4, 2, 1, 3, 0, 2, 2, 1, 2, 0, 4, 0, 4, 4, 2, 5, 2, 1, 2,\n","       2, 2, 2, 1, 2, 0, 2, 0, 1, 2, 0, 0, 4, 4, 4, 5, 4, 5, 0, 1, 4, 0,\n","       2, 3, 2, 0, 2, 4, 1, 4, 4, 5, 4, 0, 2, 1, 3, 0, 1, 4, 0, 2, 1, 5,\n","       2, 0, 4, 2, 4, 4, 1, 5, 0, 4, 5, 4, 1, 4, 5, 5, 4, 2, 4, 4, 2, 2,\n","       3, 0, 2, 4, 4, 4, 1, 4, 2, 4, 2, 2, 4, 4, 2, 0, 2, 0, 1, 5, 2, 3,\n","       0, 0, 2, 2, 2, 0, 3, 4, 0, 0, 4, 4, 4, 4])"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvazaV-7YjUO","executionInfo":{"status":"ok","timestamp":1620331963665,"user_tz":-540,"elapsed":11473,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"99640254-1139-43ef-92ed-0585538a4e93"},"source":["# BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n","\n","print (test_sentences[0])\n","print (tokenized_texts[0])\n","# UNK는 뭐지? Unknown"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS]  피말리는   일 일연속 응급실행 하다가  박 일 입원하고 퇴원 자가격리시키고 오늘 피검사결과 모든수치 다 정상돌아옴 정말 지옥까지 내려갔다가 하이파이브하고 올라온 느낌제발 건강만하자 이쁜연지공주야  개월아기돌발진호중구감소백혈구감소피말린다매일채혈돌아버리는줄건강만하자사랑해딸 피말리는   일 일연속 응급실행 년 전    피말리는   일 일연속 응급실행 하다가  박 일 입원하고 퇴원 자가격리시키고 오늘 피검사결과 모든수치 다 정상돌아옴 정말 지옥까지 내려갔다가 하이파이브하고 올라온 느낌제발 건강만하자 이쁜연지공주야  개월아기 돌발진 호중구감소 백혈구감소 피말린다 매일채혈 돌아버리는줄 건강만하자 사랑해딸  [SEP]\n","['[CLS]', '피', '##말', '##리는', '일', '일', '##연', '##속', '응', '##급', '##실', '##행', '하다', '##가', '박', '일', '입', '##원', '##하고', '퇴', '##원', '자', '##가', '##격', '##리', '##시', '##키', '##고', '오', '##늘', '피', '##검', '##사', '##결', '##과', '모든', '##수', '##치', '다', '정', '##상', '##돌', '##아', '##옴', '정', '##말', '지', '##옥', '##까지', '내', '##려', '##갔다', '##가', '하', '##이', '##파', '##이브', '##하고', '올', '##라', '##온', '느', '##낌', '##제', '##발', '건', '##강', '##만', '##하자', '이', '##쁜', '##연', '##지', '##공', '##주', '##야', '개', '##월', '##아', '##기', '##돌', '##발', '##진', '##호', '##중', '##구', '##감', '##소', '##백', '##혈', '##구', '##감', '##소', '##피', '##말', '##린다', '##매', '##일', '##채', '##혈', '##돌', '##아', '##버', '##리는', '##줄', '##건', '##강', '##만', '##하자', '##사', '##랑', '##해', '##딸', '피', '##말', '##리는', '일', '일', '##연', '##속', '응', '##급', '##실', '##행', '년', '전', '피', '##말', '##리는', '일', '일', '##연', '##속', '응', '##급', '##실', '##행', '하다', '##가', '박', '일', '입', '##원', '##하고', '퇴', '##원', '자', '##가', '##격', '##리', '##시', '##키', '##고', '오', '##늘', '피', '##검', '##사', '##결', '##과', '모든', '##수', '##치', '다', '정', '##상', '##돌', '##아', '##옴', '정', '##말', '지', '##옥', '##까지', '내', '##려', '##갔다', '##가', '하', '##이', '##파', '##이브', '##하고', '올', '##라', '##온', '느', '##낌', '##제', '##발', '건', '##강', '##만', '##하자', '이', '##쁜', '##연', '##지', '##공', '##주', '##야', '개', '##월', '##아', '##기', '돌', '##발', '##진', '호', '##중', '##구', '##감', '##소', '백', '##혈', '##구', '##감', '##소', '피', '##말', '##린다', '매', '##일', '##채', '##혈', '돌', '##아', '##버', '##리는', '##줄', '건', '##강', '##만', '##하자', '사', '##랑', '##해', '##딸', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"779647yfYnas","executionInfo":{"status":"ok","timestamp":1620331963665,"user_tz":-540,"elapsed":11459,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"6348c292-26e9-4eb0-8967-9a458af0ffa0"},"source":["# 입력 토큰의 최대 시퀀스 길이 128\n","MAX_LEN = 256\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9946,  89523,  26344,   9641,   9641,  25486,  43962,\n","         9636,  37568,  31503,  25549,  80564,  11287,   9319,   9641,\n","         9645,  14279,  12453,   9880,  14279,   9651,  11287,  45465,\n","        12692,  14040,  21039,  11664,   9580, 118762,   9946, 118625,\n","        12945,  74322,  11882,  25701,  15891,  18622,   9056,   9670,\n","        14871, 118794,  16985, 119156,   9670,  89523,   9706, 119152,\n","        18382,   8996,  26737,  84986,  11287,   9952,  10739,  46150,\n","        98789,  12453,   9583,  17342,  37093,   9041, 118713,  17730,\n","        51431,   8865,  47181,  19105,  79480,   9638, 119023,  25486,\n","        12508,  28000,  16323,  21711,   8857,  38851,  16985,  12310,\n","       118794,  51431,  18623,  20309,  41693,  17196, 105197,  22333,\n","        63218, 119433,  17196, 105197,  22333,  97146,  89523,  71104,\n","       100372,  18392, 119253, 119433, 118794,  16985,  41605,  26344,\n","       119219,  71439,  47181,  19105,  79480,  12945,  62200,  14523,\n","       118828,   9946,  89523,  26344,   9641,   9641,  25486,  43962,\n","         9636,  37568,  31503,  25549,   9018,   9665,   9946,  89523,\n","        26344,   9641,   9641,  25486,  43962,   9636,  37568,  31503,\n","        25549,  80564,  11287,   9319,   9641,   9645,  14279,  12453,\n","         9880,  14279,   9651,  11287,  45465,  12692,  14040,  21039,\n","        11664,   9580, 118762,   9946, 118625,  12945,  74322,  11882,\n","        25701,  15891,  18622,   9056,   9670,  14871, 118794,  16985,\n","       119156,   9670,  89523,   9706, 119152,  18382,   8996,  26737,\n","        84986,  11287,   9952,  10739,  46150,  98789,  12453,   9583,\n","        17342,  37093,   9041, 118713,  17730,  51431,   8865,  47181,\n","        19105,  79480,   9638, 119023,  25486,  12508,  28000,  16323,\n","        21711,   8857,  38851,  16985,  12310,   9091,  51431,  18623,\n","         9985,  41693,  17196, 105197,  22333,   9331, 119433,  17196,\n","       105197,  22333,   9946,  89523,  71104,   9258,  18392, 119253,\n","       119433,   9091,  16985,  41605,  26344, 119219,   8865,  47181,\n","        19105,  79480,   9405,  62200,  14523, 118828,    102,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SvMboXO8Yp80","executionInfo":{"status":"ok","timestamp":1620331963666,"user_tz":-540,"elapsed":11449,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"e3b8f235-e6eb-49b2-d1e6-6c2c133b32a0"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAdvRv_aYr0C","executionInfo":{"status":"ok","timestamp":1620331963667,"user_tz":-540,"elapsed":11439,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"175018f0-3418-4bb6-9332-a0342e72bb6f"},"source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(test_sentiment)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([   101,   9946,  89523,  26344,   9641,   9641,  25486,  43962,   9636,\n","         37568,  31503,  25549,  80564,  11287,   9319,   9641,   9645,  14279,\n","         12453,   9880,  14279,   9651,  11287,  45465,  12692,  14040,  21039,\n","         11664,   9580, 118762,   9946, 118625,  12945,  74322,  11882,  25701,\n","         15891,  18622,   9056,   9670,  14871, 118794,  16985, 119156,   9670,\n","         89523,   9706, 119152,  18382,   8996,  26737,  84986,  11287,   9952,\n","         10739,  46150,  98789,  12453,   9583,  17342,  37093,   9041, 118713,\n","         17730,  51431,   8865,  47181,  19105,  79480,   9638, 119023,  25486,\n","         12508,  28000,  16323,  21711,   8857,  38851,  16985,  12310, 118794,\n","         51431,  18623,  20309,  41693,  17196, 105197,  22333,  63218, 119433,\n","         17196, 105197,  22333,  97146,  89523,  71104, 100372,  18392, 119253,\n","        119433, 118794,  16985,  41605,  26344, 119219,  71439,  47181,  19105,\n","         79480,  12945,  62200,  14523, 118828,   9946,  89523,  26344,   9641,\n","          9641,  25486,  43962,   9636,  37568,  31503,  25549,   9018,   9665,\n","          9946,  89523,  26344,   9641,   9641,  25486,  43962,   9636,  37568,\n","         31503,  25549,  80564,  11287,   9319,   9641,   9645,  14279,  12453,\n","          9880,  14279,   9651,  11287,  45465,  12692,  14040,  21039,  11664,\n","          9580, 118762,   9946, 118625,  12945,  74322,  11882,  25701,  15891,\n","         18622,   9056,   9670,  14871, 118794,  16985, 119156,   9670,  89523,\n","          9706, 119152,  18382,   8996,  26737,  84986,  11287,   9952,  10739,\n","         46150,  98789,  12453,   9583,  17342,  37093,   9041, 118713,  17730,\n","         51431,   8865,  47181,  19105,  79480,   9638, 119023,  25486,  12508,\n","         28000,  16323,  21711,   8857,  38851,  16985,  12310,   9091,  51431,\n","         18623,   9985,  41693,  17196, 105197,  22333,   9331, 119433,  17196,\n","        105197,  22333,   9946,  89523,  71104,   9258,  18392, 119253, 119433,\n","          9091,  16985,  41605,  26344, 119219,   8865,  47181,  19105,  79480,\n","          9405,  62200,  14523, 118828,    102,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yfOu2-QAYtUn"},"source":["# 배치 사이즈\n","batch_size = 16\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y0wnvav-YwOQ","executionInfo":{"status":"ok","timestamp":1620331963668,"user_tz":-540,"elapsed":11421,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"2939a43f-57ac-4d87-b6bf-7fc05a904b4e"},"source":["# GPU 디바이스 이름 구함\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 디바이스 이름 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fhcy3bBYYzeA","executionInfo":{"status":"ok","timestamp":1620331963668,"user_tz":-540,"elapsed":11410,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"47291812-7235-4dcd-bbdd-a39302b537b0"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12S8ArCeY2Yw","executionInfo":{"status":"ok","timestamp":1620331969219,"user_tz":-540,"elapsed":16949,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"645f0c6d-22a4-4a47-c1c6-1351f45ba9e8"},"source":["# 분류를 위한 BERT 모델 생성\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=7)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"code","metadata":{"id":"8PnNx3AiY4Wi"},"source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 10\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBakvucnY7NH"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbLD0KMbZDgM"},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNw3dMHhZFNS","executionInfo":{"status":"ok","timestamp":1620332482871,"user_tz":-540,"elapsed":530553,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"f58795f8-f3f3-4032-b3d5-671ec6abb81a"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        print(b_labels)\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","tensor([2, 1, 4, 4, 4, 4, 5, 2, 1, 0, 5, 3, 4, 3, 0, 5], device='cuda:0')\n","tensor([3, 2, 5, 1, 2, 4, 4, 4, 1, 1, 4, 0, 0, 4, 2, 4], device='cuda:0')\n","tensor([1, 0, 1, 4, 4, 4, 5, 2, 0, 2, 2, 4, 4, 1, 0, 2], device='cuda:0')\n","tensor([1, 2, 3, 4, 4, 3, 2, 4, 1, 4, 4, 3, 4, 4, 1, 3], device='cuda:0')\n","tensor([0, 4, 0, 1, 0, 1, 1, 0, 2, 4, 1, 0, 1, 0, 0, 0], device='cuda:0')\n","tensor([4, 2, 4, 4, 4, 3, 4, 4, 3, 0, 2, 2, 4, 0, 4, 0], device='cuda:0')\n","tensor([1, 4, 3, 0, 3, 1, 4, 4, 4, 0, 0, 2, 0, 4, 5, 4], device='cuda:0')\n","tensor([2, 0, 4, 0, 4, 2, 5, 0, 0, 3, 4, 0, 2, 4, 0, 0], device='cuda:0')\n","tensor([2, 5, 5, 5, 2, 4, 5, 1, 4, 0, 4, 2, 1, 0, 0, 5], device='cuda:0')\n","tensor([3, 4, 3, 2, 2, 4, 5, 4, 0, 4, 2, 2, 2, 1, 4, 4], device='cuda:0')\n","tensor([3, 2, 0, 1, 2, 0, 5, 4, 2, 0, 4, 1, 0, 4, 2, 4], device='cuda:0')\n","tensor([2, 3, 0, 4, 4, 1, 2, 4, 4, 4, 4, 1, 2, 4, 4, 1], device='cuda:0')\n","tensor([4, 3, 0, 4, 2, 4, 4, 2, 0, 4, 4, 5, 4, 0, 1, 4], device='cuda:0')\n","tensor([0, 2, 4, 1, 2, 4, 1, 3, 2, 5, 1, 2, 2, 2, 5, 1], device='cuda:0')\n","tensor([3, 2, 4, 4, 4, 4, 4, 3, 4, 4, 0, 0, 1, 4, 4, 4], device='cuda:0')\n","tensor([2, 4, 2, 4, 0, 0, 5, 3, 4, 0, 4, 4, 0, 2, 0, 4], device='cuda:0')\n","tensor([2, 4, 3, 0, 2, 5, 0, 0, 5, 1, 0, 4, 1, 5, 5, 4], device='cuda:0')\n","tensor([2, 2, 1, 0, 2, 4, 2, 5, 4, 4, 2, 4, 4, 2, 2, 5], device='cuda:0')\n","tensor([4, 2, 5, 0, 5, 4, 5, 3, 2, 0, 4, 4, 0, 1, 4, 2], device='cuda:0')\n","tensor([2, 5, 1, 4, 4, 4, 0, 1, 2, 0, 4, 2, 4, 4, 3, 4], device='cuda:0')\n","tensor([2, 3, 4, 5, 0, 1, 5, 4, 4, 0, 4, 4, 4, 4, 1, 4], device='cuda:0')\n","tensor([4, 4, 2, 2, 2, 0, 4, 1, 3, 2, 2, 4, 0, 1, 4, 2], device='cuda:0')\n","tensor([3, 2, 4, 3, 4, 2, 5, 1, 2, 2, 1, 2, 2, 0, 2, 4], device='cuda:0')\n","tensor([2, 0, 5, 4, 5, 0, 2, 4, 3, 5, 0, 1, 1, 2, 2, 4], device='cuda:0')\n","tensor([0, 3, 2, 4, 2, 4, 0, 3, 4, 2, 1, 2, 2, 4, 2, 3], device='cuda:0')\n","tensor([2, 5, 4, 3, 4, 4, 4, 0, 5, 4, 5, 2, 1, 3, 4, 4], device='cuda:0')\n","tensor([0, 4, 4, 4, 1, 4, 3, 5, 1, 4, 0, 4, 2, 1, 0, 2], device='cuda:0')\n","tensor([4, 4, 4, 4, 2, 5, 0, 2, 0, 5, 4, 2, 1, 3, 2, 3], device='cuda:0')\n","tensor([1, 4, 2, 0, 4, 4, 4, 4, 0, 0, 2, 1, 4, 2, 2, 2], device='cuda:0')\n","tensor([1, 3, 2, 5, 0, 4, 3, 4, 3, 5, 2, 0, 1, 2, 2, 4], device='cuda:0')\n","tensor([5, 2, 2, 2, 4, 0, 2, 2, 4, 2, 3, 4, 2, 4, 1, 0], device='cuda:0')\n","tensor([3, 1, 4, 2, 4, 2, 4, 0, 4, 3, 5, 4, 2, 4, 4, 2], device='cuda:0')\n","tensor([0, 4, 1, 4, 0, 2, 0, 4, 4, 2, 0, 3, 4, 0, 2, 0], device='cuda:0')\n","tensor([4, 0, 4, 3, 0, 2, 4, 0, 4, 4, 4, 0, 2, 3, 2, 2], device='cuda:0')\n","tensor([2, 3, 0, 0, 4, 4, 4, 3, 3, 2, 5, 4, 0, 3, 2, 2], device='cuda:0')\n","tensor([1, 3, 5, 4, 1, 1, 4, 4, 4, 1, 1, 4, 3, 0, 2, 4], device='cuda:0')\n","tensor([2, 2, 2, 3, 2, 2, 1, 4, 4, 2, 3, 3, 5, 4, 1, 2], device='cuda:0')\n","tensor([4, 0, 4, 4, 4, 4, 4, 4, 1, 3, 4, 3, 2, 4, 4, 0], device='cuda:0')\n","tensor([4, 0, 5, 2, 3, 4, 4, 2, 4, 0, 1, 1, 3, 1, 1, 2], device='cuda:0')\n","tensor([0, 4, 1, 4, 5, 4, 2, 4, 4, 1, 4, 1, 2, 4, 4, 0], device='cuda:0')\n","tensor([4, 0, 0, 2, 0, 5, 4, 4, 2, 2, 2, 0, 2, 4, 4, 5], device='cuda:0')\n","tensor([2, 4, 1, 2, 4, 4, 1, 0, 2, 0, 4, 4, 1, 4, 2, 0], device='cuda:0')\n","tensor([2, 0, 4, 2, 4, 4, 4, 1, 0, 2, 1, 1, 4, 1, 1, 2], device='cuda:0')\n","tensor([2, 0, 2, 2, 2, 4, 2, 3, 4, 4, 0, 4, 4, 4, 2, 1], device='cuda:0')\n","tensor([3, 3, 2, 4, 0, 3, 4, 0, 0, 4, 4, 2, 4, 2, 2, 3], device='cuda:0')\n","tensor([2, 2, 4, 1, 5, 1, 0, 0, 0, 4, 3, 4, 4, 2, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 3, 0, 0, 3], device='cuda:0')\n","tensor([4, 5, 4, 0, 2, 4, 0, 0, 4, 2, 2, 4, 4, 2, 0, 0], device='cuda:0')\n","tensor([0, 4, 4, 2, 4, 1, 3, 2, 4, 3, 4, 4, 0, 0, 2, 0], device='cuda:0')\n","tensor([0, 0, 0, 5, 4, 1, 0, 4, 1, 4, 1, 5, 1, 5, 4, 4], device='cuda:0')\n","tensor([4, 2, 2, 0, 0, 4, 2, 2, 0, 2, 3, 4, 1, 4, 0, 4], device='cuda:0')\n","tensor([0, 5, 5, 1, 4, 4, 2, 4, 1, 0, 4, 4, 1, 2, 2, 2], device='cuda:0')\n","tensor([3, 0, 3, 0, 4, 2, 4, 0, 4, 4, 4, 0, 4, 0, 4, 5], device='cuda:0')\n","tensor([2, 2, 4, 2, 4, 1, 4, 4, 0, 4, 4, 4, 4, 2, 4, 5], device='cuda:0')\n","tensor([4, 0, 4, 5, 4, 2, 0, 4, 3, 3, 0, 4, 1, 4, 4, 0], device='cuda:0')\n","tensor([5, 0, 2, 2, 5, 5, 4, 0, 2, 3, 0, 4, 4, 2, 2, 0], device='cuda:0')\n","tensor([0, 3, 4, 0, 4, 1, 2, 4, 4, 4, 4, 2, 1, 4, 4, 3], device='cuda:0')\n","tensor([4, 4, 2, 4, 4, 2, 3, 0, 0, 0, 0, 4, 2, 4, 0, 0], device='cuda:0')\n","tensor([2, 0, 5, 2, 4, 5, 3, 4, 0, 4, 3, 4, 4, 5, 3, 0], device='cuda:0')\n","tensor([2, 4, 2, 2, 4, 3, 1, 1, 2, 3, 0, 0], device='cuda:0')\n","\n","  Average training loss: 1.68\n","  Training epcoh took: 0:00:49\n","\n","Running Validation...\n","  Accuracy: 0.35\n","  Validation took: 0:00:04\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","tensor([3, 4, 2, 2, 2, 4, 2, 4, 3, 0, 4, 2, 4, 3, 4, 2], device='cuda:0')\n","tensor([5, 5, 3, 1, 4, 5, 2, 4, 0, 3, 4, 0, 4, 4, 1, 5], device='cuda:0')\n","tensor([2, 4, 3, 2, 1, 1, 2, 1, 4, 2, 1, 3, 2, 4, 0, 4], device='cuda:0')\n","tensor([2, 4, 4, 2, 2, 4, 4, 4, 3, 0, 1, 4, 4, 1, 0, 2], device='cuda:0')\n","tensor([1, 5, 4, 1, 4, 4, 4, 4, 4, 3, 4, 1, 2, 4, 1, 2], device='cuda:0')\n","tensor([4, 4, 4, 0, 3, 0, 2, 4, 4, 4, 1, 3, 2, 5, 4, 4], device='cuda:0')\n","tensor([4, 3, 0, 0, 0, 4, 3, 2, 2, 2, 4, 1, 2, 1, 4, 4], device='cuda:0')\n","tensor([0, 0, 4, 3, 1, 4, 3, 4, 0, 4, 4, 1, 2, 1, 5, 5], device='cuda:0')\n","tensor([0, 4, 4, 0, 3, 4, 5, 3, 0, 2, 5, 4, 2, 4, 0, 5], device='cuda:0')\n","tensor([5, 3, 5, 4, 4, 4, 4, 4, 2, 3, 0, 5, 2, 3, 1, 1], device='cuda:0')\n","tensor([2, 0, 4, 4, 2, 4, 4, 1, 2, 1, 0, 4, 1, 1, 2, 2], device='cuda:0')\n","tensor([2, 4, 0, 2, 2, 4, 2, 4, 0, 4, 0, 0, 0, 4, 4, 3], device='cuda:0')\n","tensor([0, 2, 2, 0, 5, 2, 4, 2, 4, 4, 4, 2, 2, 4, 0, 0], device='cuda:0')\n","tensor([4, 2, 4, 1, 4, 4, 1, 2, 1, 0, 2, 3, 4, 4, 0, 4], device='cuda:0')\n","tensor([4, 1, 4, 1, 0, 0, 5, 4, 2, 0, 1, 4, 4, 5, 0, 2], device='cuda:0')\n","tensor([4, 5, 0, 4, 0, 0, 5, 2, 4, 4, 4, 4, 0, 4, 5, 2], device='cuda:0')\n","tensor([5, 5, 4, 4, 0, 4, 4, 4, 1, 3, 4, 4, 4, 3, 4, 3], device='cuda:0')\n","tensor([4, 3, 5, 4, 4, 4, 3, 4, 4, 4, 2, 2, 1, 2, 4, 4], device='cuda:0')\n","tensor([4, 0, 4, 2, 4, 2, 1, 2, 2, 4, 4, 4, 2, 1, 0, 2], device='cuda:0')\n","tensor([2, 1, 4, 4, 0, 4, 4, 5, 1, 4, 2, 4, 4, 0, 4, 5], device='cuda:0')\n","tensor([4, 3, 4, 5, 3, 0, 0, 4, 2, 2, 4, 0, 0, 0, 4, 3], device='cuda:0')\n","tensor([0, 4, 4, 4, 0, 2, 2, 2, 1, 2, 3, 4, 2, 0, 0, 5], device='cuda:0')\n","tensor([2, 4, 4, 4, 4, 4, 2, 2, 3, 3, 5, 4, 4, 1, 4, 1], device='cuda:0')\n","tensor([0, 0, 3, 2, 2, 4, 0, 0, 4, 2, 1, 0, 5, 0, 4, 0], device='cuda:0')\n","tensor([5, 5, 4, 2, 4, 3, 2, 2, 0, 5, 4, 4, 4, 4, 1, 2], device='cuda:0')\n","tensor([0, 0, 0, 4, 4, 2, 2, 2, 2, 0, 4, 4, 4, 4, 3, 5], device='cuda:0')\n","tensor([2, 3, 4, 5, 2, 4, 1, 2, 5, 0, 2, 2, 4, 4, 4, 3], device='cuda:0')\n","tensor([5, 3, 2, 1, 1, 5, 0, 3, 0, 3, 4, 4, 2, 2, 0, 4], device='cuda:0')\n","tensor([1, 1, 3, 0, 4, 2, 4, 3, 3, 4, 2, 4, 0, 4, 2, 0], device='cuda:0')\n","tensor([2, 2, 0, 2, 4, 3, 0, 2, 1, 1, 4, 2, 2, 2, 1, 0], device='cuda:0')\n","tensor([4, 0, 3, 4, 1, 2, 1, 0, 1, 2, 4, 4, 4, 4, 4, 3], device='cuda:0')\n","tensor([4, 1, 2, 2, 4, 4, 1, 0, 5, 4, 2, 0, 3, 5, 2, 4], device='cuda:0')\n","tensor([1, 2, 4, 4, 0, 3, 2, 0, 2, 4, 0, 1, 2, 4, 4, 4], device='cuda:0')\n","tensor([4, 1, 2, 2, 2, 4, 4, 4, 4, 2, 1, 2, 0, 0, 2, 0], device='cuda:0')\n","tensor([2, 4, 4, 5, 4, 5, 0, 5, 4, 2, 0, 1, 0, 0, 5, 1], device='cuda:0')\n","tensor([1, 0, 4, 4, 3, 4, 2, 5, 4, 4, 4, 0, 4, 2, 3, 0], device='cuda:0')\n","tensor([0, 0, 0, 0, 2, 3, 2, 3, 4, 1, 1, 2, 1, 2, 4, 0], device='cuda:0')\n","tensor([2, 3, 2, 4, 4, 5, 4, 4, 4, 4, 3, 1, 2, 2, 0, 0], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 1, 4, 5, 0, 4, 1, 0, 2, 1, 2, 2], device='cuda:0')\n","tensor([5, 0, 3, 0, 3, 1, 0, 0, 0, 4, 2, 2, 1, 2, 2, 4], device='cuda:0')\n","tensor([5, 4, 5, 2, 1, 5, 0, 2, 4, 1, 4, 4, 1, 0, 2, 0], device='cuda:0')\n","tensor([4, 2, 0, 2, 4, 0, 4, 2, 3, 2, 0, 2, 0, 4, 2, 4], device='cuda:0')\n","tensor([3, 0, 5, 4, 4, 3, 1, 2, 1, 5, 1, 0, 4, 4, 4, 1], device='cuda:0')\n","tensor([4, 4, 2, 3, 4, 2, 4, 4, 4, 1, 0, 4, 4, 2, 0, 4], device='cuda:0')\n","tensor([4, 4, 4, 5, 4, 4, 2, 1, 1, 1, 4, 4, 1, 3, 2, 0], device='cuda:0')\n","tensor([3, 2, 2, 2, 4, 1, 5, 0, 4, 2, 4, 2, 1, 0, 4, 4], device='cuda:0')\n","tensor([4, 4, 0, 0, 2, 1, 4, 2, 2, 0, 3, 0, 2, 0, 4, 0], device='cuda:0')\n","tensor([2, 2, 0, 2, 4, 4, 5, 2, 4, 4, 4, 4, 0, 0, 4, 5], device='cuda:0')\n","tensor([5, 0, 1, 1, 3, 2, 1, 4, 2, 5, 4, 4, 4, 4, 2, 2], device='cuda:0')\n","tensor([2, 2, 4, 4, 4, 4, 4, 2, 2, 0, 4, 3, 0, 0, 4, 3], device='cuda:0')\n","tensor([2, 3, 4, 2, 2, 2, 1, 4, 2, 1, 4, 1, 5, 5, 0, 4], device='cuda:0')\n","tensor([4, 0, 0, 3, 0, 4, 0, 4, 0, 2, 4, 0, 4, 4, 5, 2], device='cuda:0')\n","tensor([2, 0, 4, 2, 2, 4, 4, 0, 4, 2, 4, 1, 1, 0, 3, 4], device='cuda:0')\n","tensor([4, 2, 4, 2, 4, 2, 2, 5, 1, 4, 0, 2, 0, 0, 4, 0], device='cuda:0')\n","tensor([0, 4, 4, 4, 3, 4, 2, 4, 4, 5, 3, 2, 4, 0, 4, 2], device='cuda:0')\n","tensor([4, 4, 4, 2, 2, 3, 4, 4, 5, 0, 0, 3, 4, 5, 4, 4], device='cuda:0')\n","tensor([3, 4, 2, 4, 3, 4, 2, 3, 5, 4, 0, 1, 0, 4, 3, 3], device='cuda:0')\n","tensor([2, 0, 5, 3, 1, 2, 2, 0, 4, 0, 4, 0, 4, 4, 0, 5], device='cuda:0')\n","tensor([0, 3, 4, 3, 0, 4, 1, 0, 4, 4, 5, 2, 1, 1, 0, 0], device='cuda:0')\n","tensor([2, 1, 2, 4, 4, 0, 0, 0, 0, 4, 3, 2], device='cuda:0')\n","\n","  Average training loss: 1.36\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:04\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","tensor([3, 2, 3, 3, 0, 5, 1, 2, 0, 0, 0, 0, 0, 2, 2, 4], device='cuda:0')\n","tensor([4, 0, 4, 4, 5, 4, 4, 2, 1, 4, 1, 5, 2, 1, 0, 2], device='cuda:0')\n","tensor([1, 4, 0, 4, 4, 2, 2, 4, 4, 4, 4, 0, 2, 4, 2, 4], device='cuda:0')\n","tensor([2, 0, 3, 0, 3, 4, 2, 0, 1, 4, 3, 3, 1, 2, 2, 1], device='cuda:0')\n","tensor([3, 2, 4, 4, 2, 5, 1, 2, 4, 3, 1, 4, 4, 2, 4, 1], device='cuda:0')\n","tensor([4, 4, 2, 1, 4, 4, 3, 4, 3, 4, 0, 4, 2, 0, 4, 4], device='cuda:0')\n","tensor([2, 5, 2, 4, 5, 5, 3, 5, 2, 2, 4, 2, 3, 1, 0, 5], device='cuda:0')\n","tensor([3, 4, 0, 2, 4, 2, 4, 3, 4, 4, 0, 4, 4, 0, 2, 2], device='cuda:0')\n","tensor([1, 2, 0, 2, 4, 1, 1, 2, 0, 1, 0, 4, 0, 4, 4, 2], device='cuda:0')\n","tensor([0, 4, 4, 3, 2, 4, 2, 4, 2, 1, 4, 2, 0, 4, 3, 4], device='cuda:0')\n","tensor([4, 4, 3, 2, 2, 4, 4, 4, 0, 3, 0, 4, 1, 0, 4, 4], device='cuda:0')\n","tensor([5, 4, 4, 4, 0, 5, 5, 1, 4, 2, 4, 5, 0, 0, 0, 5], device='cuda:0')\n","tensor([4, 2, 4, 5, 0, 2, 1, 3, 2, 4, 2, 0, 0, 0, 2, 4], device='cuda:0')\n","tensor([4, 3, 0, 5, 4, 5, 2, 2, 4, 4, 4, 4, 0, 4, 4, 2], device='cuda:0')\n","tensor([2, 4, 2, 0, 3, 2, 0, 1, 0, 3, 4, 1, 4, 2, 4, 2], device='cuda:0')\n","tensor([4, 2, 2, 0, 4, 5, 2, 4, 4, 4, 4, 2, 4, 4, 2, 0], device='cuda:0')\n","tensor([1, 4, 4, 2, 4, 2, 2, 0, 2, 2, 0, 4, 2, 4, 5, 3], device='cuda:0')\n","tensor([4, 4, 0, 0, 4, 1, 4, 4, 2, 4, 5, 4, 4, 0, 2, 1], device='cuda:0')\n","tensor([2, 2, 4, 4, 0, 0, 4, 4, 4, 0, 4, 3, 4, 2, 2, 0], device='cuda:0')\n","tensor([1, 4, 3, 0, 3, 2, 0, 0, 1, 2, 2, 2, 0, 5, 5, 0], device='cuda:0')\n","tensor([1, 2, 5, 4, 1, 4, 3, 2, 4, 3, 1, 2, 3, 0, 3, 2], device='cuda:0')\n","tensor([3, 1, 2, 0, 4, 4, 0, 4, 4, 2, 4, 4, 4, 2, 4, 1], device='cuda:0')\n","tensor([1, 4, 0, 2, 2, 1, 4, 4, 2, 3, 4, 0, 2, 3, 2, 4], device='cuda:0')\n","tensor([2, 4, 5, 2, 0, 5, 4, 4, 2, 4, 0, 5, 4, 2, 2, 1], device='cuda:0')\n","tensor([4, 4, 2, 4, 1, 4, 1, 2, 1, 4, 4, 0, 0, 4, 2, 4], device='cuda:0')\n","tensor([0, 2, 2, 2, 4, 2, 2, 4, 5, 3, 4, 3, 4, 2, 0, 5], device='cuda:0')\n","tensor([0, 2, 4, 2, 2, 4, 4, 3, 4, 4, 1, 3, 4, 0, 0, 4], device='cuda:0')\n","tensor([4, 3, 2, 4, 2, 0, 4, 4, 0, 2, 4, 1, 0, 4, 4, 0], device='cuda:0')\n","tensor([4, 0, 4, 0, 4, 4, 4, 1, 1, 2, 2, 0, 4, 4, 0, 0], device='cuda:0')\n","tensor([3, 2, 0, 1, 5, 0, 3, 4, 5, 2, 3, 3, 5, 5, 4, 4], device='cuda:0')\n","tensor([4, 0, 4, 4, 4, 3, 4, 1, 3, 0, 3, 4, 2, 3, 2, 4], device='cuda:0')\n","tensor([2, 0, 0, 0, 2, 2, 4, 4, 5, 0, 4, 2, 5, 4, 0, 4], device='cuda:0')\n","tensor([1, 4, 2, 0, 2, 2, 2, 1, 4, 2, 0, 0, 4, 1, 0, 3], device='cuda:0')\n","tensor([0, 2, 3, 2, 3, 0, 2, 5, 4, 0, 3, 4, 4, 4, 5, 4], device='cuda:0')\n","tensor([4, 0, 4, 0, 2, 4, 2, 5, 0, 2, 0, 4, 2, 4, 2, 5], device='cuda:0')\n","tensor([4, 1, 4, 1, 1, 2, 4, 5, 2, 5, 4, 0, 0, 2, 4, 0], device='cuda:0')\n","tensor([1, 1, 2, 2, 4, 0, 2, 2, 0, 0, 3, 5, 4, 3, 0, 4], device='cuda:0')\n","tensor([4, 0, 5, 2, 4, 5, 4, 5, 4, 4, 1, 0, 4, 0, 0, 1], device='cuda:0')\n","tensor([0, 4, 4, 0, 4, 1, 4, 4, 4, 2, 4, 4, 4, 5, 2, 2], device='cuda:0')\n","tensor([1, 1, 4, 3, 4, 3, 2, 4, 0, 2, 4, 4, 0, 4, 4, 0], device='cuda:0')\n","tensor([0, 5, 1, 0, 5, 3, 5, 2, 1, 5, 4, 3, 2, 1, 0, 0], device='cuda:0')\n","tensor([1, 4, 1, 0, 4, 2, 2, 0, 2, 0, 2, 2, 4, 3, 4, 1], device='cuda:0')\n","tensor([0, 0, 0, 4, 3, 4, 1, 4, 4, 5, 4, 4, 2, 0, 2, 4], device='cuda:0')\n","tensor([2, 0, 1, 3, 4, 3, 1, 1, 2, 1, 4, 4, 1, 4, 1, 4], device='cuda:0')\n","tensor([1, 2, 4, 0, 3, 4, 0, 1, 0, 0, 0, 0, 0, 5, 2, 2], device='cuda:0')\n","tensor([2, 2, 4, 0, 1, 4, 1, 4, 1, 1, 4, 4, 4, 0, 2, 0], device='cuda:0')\n","tensor([4, 4, 4, 2, 4, 0, 0, 5, 4, 4, 5, 2, 5, 0, 4, 4], device='cuda:0')\n","tensor([4, 0, 0, 2, 4, 2, 1, 5, 0, 4, 3, 3, 0, 0, 2, 1], device='cuda:0')\n","tensor([4, 4, 4, 2, 1, 2, 4, 4, 4, 2, 0, 4, 2, 4, 4, 5], device='cuda:0')\n","tensor([4, 4, 0, 2, 4, 3, 0, 2, 4, 4, 2, 2, 5, 2, 4, 3], device='cuda:0')\n","tensor([2, 4, 2, 5, 4, 5, 4, 3, 4, 3, 2, 4, 4, 0, 1, 4], device='cuda:0')\n","tensor([4, 1, 2, 3, 0, 0, 5, 4, 2, 3, 3, 5, 2, 4, 4, 5], device='cuda:0')\n","tensor([4, 4, 4, 4, 5, 4, 4, 2, 3, 4, 4, 0, 1, 1, 2, 2], device='cuda:0')\n","tensor([4, 1, 3, 4, 4, 4, 4, 0, 4, 4, 4, 2, 4, 1, 2, 2], device='cuda:0')\n","tensor([0, 4, 4, 0, 4, 0, 2, 2, 3, 3, 5, 4, 3, 4, 1, 4], device='cuda:0')\n","tensor([2, 4, 1, 0, 4, 1, 0, 2, 4, 2, 0, 4, 4, 3, 4, 4], device='cuda:0')\n","tensor([4, 3, 3, 2, 1, 1, 0, 4, 1, 4, 2, 4, 4, 1, 5, 3], device='cuda:0')\n","tensor([3, 2, 3, 1, 5, 2, 4, 5, 1, 0, 4, 0, 4, 4, 4, 2], device='cuda:0')\n","tensor([1, 0, 4, 3, 1, 4, 2, 4, 1, 5, 4, 2, 4, 4, 0, 4], device='cuda:0')\n","tensor([4, 2, 1, 0, 1, 5, 4, 0, 0, 2, 2, 2], device='cuda:0')\n","\n","  Average training loss: 1.03\n","  Training epcoh took: 0:00:48\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation took: 0:00:04\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","tensor([4, 0, 4, 4, 1, 2, 2, 3, 4, 3, 2, 5, 3, 0, 2, 0], device='cuda:0')\n","tensor([4, 2, 0, 2, 4, 2, 5, 0, 2, 4, 2, 1, 2, 4, 5, 4], device='cuda:0')\n","tensor([2, 4, 1, 5, 0, 4, 3, 4, 4, 0, 4, 0, 5, 4, 2, 4], device='cuda:0')\n","tensor([0, 0, 3, 0, 4, 1, 1, 1, 1, 1, 4, 3, 1, 2, 4, 2], device='cuda:0')\n","tensor([0, 4, 0, 2, 2, 5, 2, 1, 3, 2, 4, 2, 4, 4, 4, 0], device='cuda:0')\n","tensor([4, 0, 4, 0, 4, 1, 1, 0, 2, 2, 2, 0, 2, 1, 2, 2], device='cuda:0')\n","tensor([2, 5, 4, 2, 4, 2, 0, 1, 4, 5, 1, 2, 0, 2, 0, 0], device='cuda:0')\n","tensor([0, 4, 1, 4, 4, 1, 2, 2, 0, 1, 2, 4, 0, 4, 3, 4], device='cuda:0')\n","tensor([4, 3, 1, 3, 2, 1, 4, 4, 4, 4, 1, 4, 4, 5, 2, 2], device='cuda:0')\n","tensor([1, 2, 0, 0, 4, 2, 5, 0, 0, 3, 4, 5, 0, 5, 5, 4], device='cuda:0')\n","tensor([2, 0, 4, 1, 0, 4, 4, 1, 4, 4, 5, 4, 0, 0, 0, 3], device='cuda:0')\n","tensor([4, 2, 0, 1, 5, 5, 5, 4, 5, 5, 2, 2, 4, 2, 2, 1], device='cuda:0')\n","tensor([4, 4, 4, 1, 3, 1, 4, 4, 2, 3, 4, 2, 4, 5, 2, 3], device='cuda:0')\n","tensor([0, 3, 1, 0, 4, 4, 4, 0, 1, 4, 4, 2, 0, 0, 5, 2], device='cuda:0')\n","tensor([0, 2, 2, 3, 1, 0, 0, 4, 0, 4, 0, 2, 2, 2, 4, 2], device='cuda:0')\n","tensor([2, 2, 3, 0, 5, 4, 3, 4, 4, 4, 4, 2, 4, 0, 0, 4], device='cuda:0')\n","tensor([3, 4, 1, 0, 3, 4, 2, 1, 2, 4, 3, 4, 2, 2, 1, 3], device='cuda:0')\n","tensor([2, 2, 4, 4, 4, 2, 0, 4, 4, 0, 2, 4, 4, 0, 4, 2], device='cuda:0')\n","tensor([4, 0, 4, 2, 0, 4, 4, 0, 2, 3, 0, 0, 4, 4, 0, 4], device='cuda:0')\n","tensor([2, 2, 0, 4, 4, 0, 2, 0, 0, 2, 1, 3, 1, 4, 4, 2], device='cuda:0')\n","tensor([5, 4, 4, 4, 4, 4, 2, 0, 4, 4, 0, 4, 2, 4, 4, 0], device='cuda:0')\n","tensor([4, 2, 5, 2, 2, 0, 3, 1, 3, 2, 2, 5, 5, 4, 0, 4], device='cuda:0')\n","tensor([4, 4, 4, 0, 1, 4, 0, 1, 0, 4, 3, 3, 4, 5, 2, 1], device='cuda:0')\n","tensor([4, 2, 2, 2, 2, 4, 5, 0, 0, 5, 4, 5, 2, 1, 2, 2], device='cuda:0')\n","tensor([5, 4, 5, 4, 1, 1, 4, 1, 0, 4, 4, 1, 2, 4, 3, 4], device='cuda:0')\n","tensor([4, 1, 2, 4, 2, 3, 2, 0, 0, 2, 5, 2, 3, 5, 5, 3], device='cuda:0')\n","tensor([2, 2, 2, 2, 5, 4, 4, 2, 0, 1, 4, 0, 2, 3, 1, 4], device='cuda:0')\n","tensor([0, 4, 3, 1, 2, 4, 2, 0, 2, 0, 0, 4, 2, 4, 4, 4], device='cuda:0')\n","tensor([3, 2, 4, 1, 2, 4, 5, 0, 3, 2, 4, 4, 0, 2, 3, 0], device='cuda:0')\n","tensor([2, 2, 4, 2, 4, 0, 4, 4, 4, 0, 0, 0, 2, 4, 2, 4], device='cuda:0')\n","tensor([4, 0, 2, 2, 4, 3, 4, 0, 2, 4, 4, 1, 4, 1, 4, 4], device='cuda:0')\n","tensor([4, 2, 0, 4, 2, 4, 4, 4, 4, 3, 2, 2, 4, 4, 4, 4], device='cuda:0')\n","tensor([0, 4, 4, 5, 1, 4, 4, 1, 4, 0, 4, 3, 4, 0, 2, 3], device='cuda:0')\n","tensor([2, 4, 3, 5, 4, 3, 0, 3, 0, 4, 4, 3, 2, 4, 0, 3], device='cuda:0')\n","tensor([4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 1, 3, 2, 3, 1, 5], device='cuda:0')\n","tensor([4, 0, 4, 4, 4, 2, 4, 1, 2, 4, 4, 1, 2, 4, 2, 2], device='cuda:0')\n","tensor([3, 3, 0, 4, 4, 0, 5, 3, 2, 4, 2, 2, 4, 0, 1, 2], device='cuda:0')\n","tensor([3, 4, 4, 4, 0, 1, 3, 2, 1, 4, 4, 4, 2, 2, 5, 3], device='cuda:0')\n","tensor([4, 3, 3, 2, 0, 0, 4, 0, 0, 5, 1, 4, 4, 1, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 0, 3, 5, 4, 1, 1, 5, 5, 4, 4, 0, 2], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 2, 0, 2, 4, 1, 4, 0, 0, 4, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 1, 4, 5, 2, 2, 0, 5, 4, 0, 0, 4, 4, 1], device='cuda:0')\n","tensor([0, 2, 4, 0, 4, 1, 1, 2, 0, 1, 4, 2, 2, 1, 4, 0], device='cuda:0')\n","tensor([4, 2, 5, 1, 0, 1, 4, 4, 5, 2, 0, 4, 4, 1, 4, 0], device='cuda:0')\n","tensor([0, 2, 0, 4, 0, 0, 1, 4, 4, 5, 4, 5, 4, 2, 5, 1], device='cuda:0')\n","tensor([2, 0, 4, 4, 2, 1, 5, 3, 1, 4, 3, 4, 2, 4, 2, 4], device='cuda:0')\n","tensor([4, 4, 2, 4, 1, 2, 4, 5, 4, 4, 2, 2, 5, 3, 2, 2], device='cuda:0')\n","tensor([0, 3, 0, 1, 4, 4, 2, 2, 0, 2, 4, 0, 0, 1, 0, 4], device='cuda:0')\n","tensor([2, 4, 4, 0, 2, 1, 4, 5, 2, 0, 4, 3, 4, 4, 4, 1], device='cuda:0')\n","tensor([2, 2, 2, 0, 0, 0, 1, 4, 4, 4, 0, 5, 0, 2, 2, 0], device='cuda:0')\n","tensor([5, 2, 4, 1, 0, 1, 2, 1, 2, 5, 4, 0, 3, 1, 4, 4], device='cuda:0')\n","tensor([4, 4, 0, 4, 3, 4, 3, 4, 2, 2, 4, 0, 4, 4, 0, 0], device='cuda:0')\n","tensor([4, 4, 4, 5, 4, 2, 4, 5, 2, 4, 5, 3, 3, 2, 2, 4], device='cuda:0')\n","tensor([3, 4, 3, 3, 4, 2, 3, 4, 4, 4, 3, 3, 0, 5, 2, 4], device='cuda:0')\n","tensor([1, 1, 0, 2, 2, 1, 4, 4, 5, 4, 4, 2, 1, 2, 3, 3], device='cuda:0')\n","tensor([0, 2, 4, 3, 0, 2, 4, 4, 4, 5, 2, 0, 4, 4, 4, 3], device='cuda:0')\n","tensor([0, 3, 2, 3, 1, 2, 0, 4, 5, 1, 4, 1, 2, 0, 0, 0], device='cuda:0')\n","tensor([4, 0, 2, 4, 1, 4, 2, 0, 4, 4, 4, 4, 1, 4, 1, 4], device='cuda:0')\n","tensor([2, 3, 2, 4, 2, 2, 0, 0, 0, 0, 4, 3, 0, 0, 5, 0], device='cuda:0')\n","tensor([4, 4, 3, 5, 4, 4, 4, 2, 2, 4, 1, 0], device='cuda:0')\n","\n","  Average training loss: 0.73\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation took: 0:00:04\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","tensor([5, 4, 4, 4, 2, 2, 4, 0, 0, 5, 1, 2, 4, 4, 0, 1], device='cuda:0')\n","tensor([4, 4, 4, 0, 4, 1, 2, 2, 4, 3, 5, 4, 4, 4, 0, 0], device='cuda:0')\n","tensor([3, 3, 2, 2, 2, 0, 5, 0, 2, 0, 1, 0, 0, 4, 5, 1], device='cuda:0')\n","tensor([4, 3, 2, 4, 3, 3, 2, 4, 4, 4, 5, 1, 5, 4, 5, 4], device='cuda:0')\n","tensor([2, 0, 3, 4, 4, 4, 3, 4, 4, 2, 2, 2, 4, 2, 4, 3], device='cuda:0')\n","tensor([2, 4, 0, 0, 4, 4, 2, 2, 3, 4, 4, 4, 2, 4, 1, 4], device='cuda:0')\n","tensor([3, 0, 3, 1, 4, 1, 3, 2, 2, 1, 0, 5, 3, 5, 1, 2], device='cuda:0')\n","tensor([2, 3, 0, 4, 4, 2, 3, 4, 0, 0, 4, 5, 2, 4, 2, 2], device='cuda:0')\n","tensor([2, 0, 5, 0, 3, 5, 4, 4, 4, 4, 4, 5, 1, 5, 2, 4], device='cuda:0')\n","tensor([2, 5, 1, 4, 1, 0, 4, 1, 0, 3, 1, 4, 4, 4, 4, 0], device='cuda:0')\n","tensor([1, 1, 1, 2, 4, 4, 3, 0, 4, 2, 4, 4, 0, 1, 2, 0], device='cuda:0')\n","tensor([1, 3, 2, 0, 4, 0, 2, 4, 1, 2, 4, 1, 4, 4, 0, 0], device='cuda:0')\n","tensor([4, 5, 0, 4, 3, 1, 0, 4, 4, 0, 2, 1, 1, 0, 3, 4], device='cuda:0')\n","tensor([4, 0, 4, 1, 4, 2, 2, 3, 2, 4, 2, 2, 4, 0, 0, 0], device='cuda:0')\n","tensor([4, 1, 4, 0, 0, 0, 3, 2, 1, 1, 2, 0, 4, 4, 2, 5], device='cuda:0')\n","tensor([2, 0, 1, 0, 5, 2, 2, 4, 0, 4, 1, 4, 0, 4, 5, 1], device='cuda:0')\n","tensor([2, 2, 0, 1, 0, 4, 2, 2, 0, 4, 2, 4, 4, 5, 1, 4], device='cuda:0')\n","tensor([1, 2, 1, 2, 2, 4, 2, 2, 1, 4, 3, 0, 0, 4, 2, 2], device='cuda:0')\n","tensor([0, 4, 2, 4, 0, 4, 3, 3, 0, 5, 1, 3, 4, 2, 5, 2], device='cuda:0')\n","tensor([2, 3, 2, 4, 3, 4, 5, 3, 2, 2, 5, 2, 0, 2, 4, 4], device='cuda:0')\n","tensor([4, 4, 2, 1, 0, 4, 4, 4, 5, 5, 0, 2, 0, 4, 4, 4], device='cuda:0')\n","tensor([4, 0, 1, 2, 3, 4, 4, 1, 5, 1, 0, 4, 2, 0, 2, 4], device='cuda:0')\n","tensor([2, 4, 4, 0, 5, 2, 0, 2, 4, 2, 4, 2, 4, 3, 1, 4], device='cuda:0')\n","tensor([3, 0, 1, 0, 0, 4, 4, 4, 1, 1, 4, 2, 4, 0, 2, 0], device='cuda:0')\n","tensor([5, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 1, 5, 4, 2, 2], device='cuda:0')\n","tensor([0, 2, 4, 3, 4, 0, 0, 3, 2, 5, 4, 4, 0, 4, 2, 4], device='cuda:0')\n","tensor([3, 4, 4, 0, 4, 0, 4, 2, 4, 4, 2, 0, 0, 2, 1, 4], device='cuda:0')\n","tensor([2, 3, 4, 2, 4, 3, 2, 2, 0, 0, 0, 2, 2, 5, 1, 1], device='cuda:0')\n","tensor([1, 2, 4, 4, 2, 4, 3, 5, 2, 1, 0, 2, 4, 4, 3, 2], device='cuda:0')\n","tensor([4, 4, 4, 2, 4, 4, 4, 4, 0, 1, 0, 0, 4, 0, 4, 1], device='cuda:0')\n","tensor([4, 3, 0, 2, 4, 0, 4, 0, 1, 1, 3, 5, 2, 0, 4, 2], device='cuda:0')\n","tensor([5, 4, 3, 2, 2, 0, 4, 4, 3, 2, 0, 4, 4, 2, 4, 4], device='cuda:0')\n","tensor([4, 2, 0, 2, 1, 5, 4, 3, 2, 0, 4, 3, 0, 0, 4, 4], device='cuda:0')\n","tensor([4, 2, 2, 5, 3, 4, 1, 0, 0, 3, 1, 4, 4, 5, 4, 2], device='cuda:0')\n","tensor([3, 4, 4, 5, 2, 4, 0, 3, 4, 0, 0, 0, 5, 4, 4, 2], device='cuda:0')\n","tensor([0, 2, 4, 1, 4, 2, 2, 5, 4, 4, 4, 4, 1, 3, 3, 5], device='cuda:0')\n","tensor([3, 2, 3, 3, 4, 4, 1, 0, 1, 3, 0, 4, 4, 4, 4, 4], device='cuda:0')\n","tensor([3, 5, 4, 4, 4, 4, 0, 0, 4, 4, 4, 2, 4, 1, 5, 2], device='cuda:0')\n","tensor([4, 4, 2, 4, 0, 1, 3, 4, 0, 2, 0, 4, 4, 1, 4, 2], device='cuda:0')\n","tensor([1, 0, 5, 0, 0, 3, 4, 1, 5, 4, 5, 0, 4, 0, 0, 4], device='cuda:0')\n","tensor([4, 2, 4, 4, 4, 3, 0, 3, 2, 0, 4, 2, 0, 2, 0, 0], device='cuda:0')\n","tensor([4, 4, 2, 1, 5, 4, 1, 0, 2, 4, 4, 2, 0, 4, 4, 4], device='cuda:0')\n","tensor([3, 1, 0, 1, 5, 4, 4, 2, 4, 5, 2, 2, 4, 4, 2, 4], device='cuda:0')\n","tensor([0, 4, 4, 4, 0, 4, 0, 4, 1, 0, 4, 5, 4, 2, 4, 4], device='cuda:0')\n","tensor([4, 1, 2, 2, 5, 4, 4, 2, 4, 3, 3, 2, 0, 2, 0, 4], device='cuda:0')\n","tensor([4, 2, 0, 3, 4, 0, 0, 2, 2, 4, 2, 2, 0, 2, 4, 2], device='cuda:0')\n","tensor([4, 0, 4, 1, 4, 4, 0, 1, 2, 2, 2, 1, 4, 4, 4, 2], device='cuda:0')\n","tensor([4, 2, 0, 5, 0, 0, 5, 2, 0, 2, 2, 4, 2, 2, 2, 3], device='cuda:0')\n","tensor([1, 0, 1, 0, 4, 3, 0, 4, 3, 4, 2, 5, 4, 1, 2, 0], device='cuda:0')\n","tensor([4, 4, 2, 4, 0, 4, 4, 0, 1, 4, 4, 0, 4, 2, 5, 0], device='cuda:0')\n","tensor([4, 2, 0, 4, 2, 3, 4, 2, 5, 2, 2, 1, 4, 5, 4, 4], device='cuda:0')\n","tensor([0, 0, 0, 1, 4, 1, 3, 2, 4, 0, 0, 1, 4, 4, 1, 2], device='cuda:0')\n","tensor([4, 2, 4, 1, 4, 3, 4, 0, 4, 3, 2, 4, 1, 4, 2, 2], device='cuda:0')\n","tensor([5, 4, 3, 0, 4, 1, 4, 4, 2, 4, 3, 2, 2, 4, 0, 1], device='cuda:0')\n","tensor([5, 2, 5, 1, 2, 5, 2, 1, 3, 4, 2, 2, 4, 0, 0, 2], device='cuda:0')\n","tensor([4, 4, 2, 4, 4, 0, 0, 4, 2, 4, 1, 4, 2, 3, 0, 5], device='cuda:0')\n","tensor([4, 2, 3, 2, 3, 4, 1, 4, 4, 2, 3, 0, 2, 4, 5, 2], device='cuda:0')\n","tensor([4, 4, 3, 0, 3, 4, 2, 4, 5, 0, 2, 1, 1, 2, 1, 2], device='cuda:0')\n","tensor([4, 4, 1, 2, 4, 0, 2, 3, 5, 2, 4, 4, 0, 2, 4, 4], device='cuda:0')\n","tensor([1, 4, 5, 0, 5, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n","\n","  Average training loss: 0.49\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation took: 0:00:04\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","tensor([1, 3, 4, 2, 2, 1, 4, 4, 4, 4, 2, 0, 2, 0, 2, 0], device='cuda:0')\n","tensor([4, 5, 5, 3, 4, 4, 2, 4, 0, 0, 3, 0, 4, 2, 4, 2], device='cuda:0')\n","tensor([5, 0, 3, 3, 0, 1, 2, 1, 1, 4, 0, 2, 2, 4, 3, 4], device='cuda:0')\n","tensor([5, 5, 0, 4, 3, 3, 1, 1, 4, 0, 2, 2, 0, 2, 3, 1], device='cuda:0')\n","tensor([1, 4, 1, 1, 0, 2, 1, 4, 2, 4, 4, 4, 4, 2, 2, 5], device='cuda:0')\n","tensor([4, 4, 0, 2, 5, 4, 4, 1, 4, 0, 1, 4, 2, 4, 3, 4], device='cuda:0')\n","tensor([4, 1, 2, 0, 0, 1, 2, 4, 2, 3, 4, 2, 2, 4, 2, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 4, 4, 5, 3, 4, 0, 4, 4, 4, 4, 3], device='cuda:0')\n","tensor([2, 4, 4, 3, 4, 0, 4, 3, 0, 4, 4, 4, 4, 0, 4, 4], device='cuda:0')\n","tensor([4, 2, 1, 0, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 3, 3], device='cuda:0')\n","tensor([2, 3, 1, 3, 0, 0, 4, 2, 1, 4, 1, 4, 0, 1, 2, 4], device='cuda:0')\n","tensor([2, 1, 4, 5, 1, 4, 0, 4, 5, 2, 4, 4, 4, 2, 2, 2], device='cuda:0')\n","tensor([0, 2, 0, 4, 4, 2, 1, 3, 0, 2, 4, 3, 3, 2, 4, 4], device='cuda:0')\n","tensor([4, 2, 0, 2, 4, 4, 4, 5, 4, 3, 0, 0, 4, 1, 3, 4], device='cuda:0')\n","tensor([4, 2, 4, 3, 3, 4, 1, 1, 4, 4, 5, 0, 0, 2, 5, 4], device='cuda:0')\n","tensor([0, 2, 2, 0, 4, 1, 0, 0, 5, 4, 2, 0, 0, 0, 0, 0], device='cuda:0')\n","tensor([5, 4, 4, 5, 2, 2, 1, 0, 2, 4, 0, 0, 4, 4, 0, 1], device='cuda:0')\n","tensor([4, 2, 3, 1, 3, 5, 0, 2, 4, 0, 2, 4, 0, 4, 2, 4], device='cuda:0')\n","tensor([5, 4, 2, 0, 4, 3, 3, 4, 3, 0, 1, 4, 4, 4, 2, 4], device='cuda:0')\n","tensor([4, 4, 4, 0, 1, 2, 0, 4, 4, 0, 2, 3, 3, 5, 4, 0], device='cuda:0')\n","tensor([2, 0, 2, 0, 0, 4, 4, 1, 4, 4, 0, 0, 2, 1, 2, 4], device='cuda:0')\n","tensor([2, 3, 4, 0, 4, 4, 4, 4, 0, 0, 4, 0, 4, 2, 4, 5], device='cuda:0')\n","tensor([1, 4, 2, 0, 4, 1, 4, 2, 1, 0, 3, 1, 3, 4, 4, 0], device='cuda:0')\n","tensor([4, 2, 5, 4, 3, 0, 2, 4, 4, 3, 2, 4, 3, 0, 2, 2], device='cuda:0')\n","tensor([4, 2, 4, 4, 2, 4, 4, 2, 0, 0, 0, 4, 4, 1, 4, 2], device='cuda:0')\n","tensor([3, 4, 4, 4, 4, 5, 1, 2, 2, 5, 4, 4, 4, 3, 2, 0], device='cuda:0')\n","tensor([3, 4, 4, 0, 0, 2, 0, 5, 1, 4, 4, 5, 5, 5, 0, 4], device='cuda:0')\n","tensor([0, 4, 0, 0, 4, 0, 0, 2, 4, 3, 3, 3, 4, 0, 0, 4], device='cuda:0')\n","tensor([4, 1, 5, 4, 2, 4, 0, 2, 0, 0, 5, 1, 3, 0, 4, 0], device='cuda:0')\n","tensor([0, 0, 4, 4, 4, 2, 2, 0, 1, 1, 0, 4, 0, 0, 1, 2], device='cuda:0')\n","tensor([0, 5, 0, 4, 4, 0, 0, 0, 4, 2, 4, 4, 0, 0, 3, 4], device='cuda:0')\n","tensor([5, 4, 1, 5, 4, 0, 2, 4, 4, 2, 4, 2, 2, 3, 2, 4], device='cuda:0')\n","tensor([4, 5, 2, 2, 4, 3, 2, 4, 1, 4, 4, 2, 4, 2, 4, 2], device='cuda:0')\n","tensor([0, 2, 1, 3, 4, 0, 1, 5, 4, 4, 1, 2, 5, 2, 3, 4], device='cuda:0')\n","tensor([1, 3, 4, 2, 0, 2, 4, 0, 4, 4, 5, 0, 2, 2, 1, 3], device='cuda:0')\n","tensor([1, 4, 0, 0, 2, 3, 1, 3, 4, 5, 2, 4, 4, 2, 4, 5], device='cuda:0')\n","tensor([4, 4, 2, 2, 0, 4, 3, 1, 4, 2, 2, 2, 2, 4, 1, 4], device='cuda:0')\n","tensor([3, 4, 0, 4, 4, 2, 3, 2, 3, 4, 4, 2, 3, 2, 4, 4], device='cuda:0')\n","tensor([0, 4, 1, 4, 4, 0, 4, 3, 0, 3, 5, 5, 5, 4, 4, 2], device='cuda:0')\n","tensor([1, 4, 1, 3, 2, 2, 0, 0, 4, 5, 4, 1, 2, 2, 2, 3], device='cuda:0')\n","tensor([4, 3, 4, 2, 4, 2, 2, 2, 5, 5, 0, 2, 2, 0, 4, 5], device='cuda:0')\n","tensor([4, 0, 4, 2, 3, 1, 4, 4, 0, 0, 2, 1, 0, 0, 0, 2], device='cuda:0')\n","tensor([2, 4, 5, 4, 5, 2, 2, 4, 4, 4, 1, 4, 2, 3, 1, 2], device='cuda:0')\n","tensor([4, 2, 1, 4, 4, 4, 1, 0, 2, 0, 2, 2, 4, 5, 0, 2], device='cuda:0')\n","tensor([5, 2, 2, 2, 4, 2, 4, 4, 2, 1, 0, 5, 2, 2, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 1, 2, 0, 2, 5, 2, 4, 4, 4, 0, 4], device='cuda:0')\n","tensor([2, 2, 4, 0, 4, 5, 2, 1, 4, 4, 2, 0, 0, 2, 4, 1], device='cuda:0')\n","tensor([4, 4, 0, 4, 2, 0, 4, 0, 4, 0, 5, 4, 0, 4, 1, 1], device='cuda:0')\n","tensor([5, 4, 3, 2, 4, 0, 3, 4, 2, 3, 2, 0, 1, 1, 2, 2], device='cuda:0')\n","tensor([4, 4, 1, 4, 4, 4, 4, 2, 0, 4, 3, 1, 0, 2, 5, 0], device='cuda:0')\n","tensor([5, 4, 4, 5, 4, 0, 0, 0, 1, 4, 5, 0, 2, 2, 4, 2], device='cuda:0')\n","tensor([4, 4, 4, 2, 0, 2, 3, 1, 4, 5, 2, 1, 4, 0, 2, 3], device='cuda:0')\n","tensor([4, 4, 4, 1, 0, 2, 1, 4, 1, 4, 2, 4, 0, 4, 1, 1], device='cuda:0')\n","tensor([4, 0, 5, 1, 2, 2, 4, 4, 0, 4, 0, 2, 4, 3, 4, 5], device='cuda:0')\n","tensor([0, 1, 4, 2, 1, 4, 4, 4, 0, 0, 4, 1, 3, 3, 0, 2], device='cuda:0')\n","tensor([3, 4, 1, 1, 2, 0, 4, 2, 0, 1, 4, 2, 4, 4, 1, 2], device='cuda:0')\n","tensor([1, 2, 4, 1, 2, 4, 2, 5, 5, 2, 2, 4, 1, 3, 3, 4], device='cuda:0')\n","tensor([4, 4, 5, 5, 4, 4, 4, 4, 4, 0, 2, 3, 5, 0, 4, 4], device='cuda:0')\n","tensor([5, 5, 1, 4, 2, 4, 4, 4, 2, 1, 4, 1, 3, 0, 2, 5], device='cuda:0')\n","tensor([4, 4, 0, 2, 0, 2, 2, 2, 2, 0, 3, 3], device='cuda:0')\n","\n","  Average training loss: 0.34\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation took: 0:00:04\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","tensor([1, 3, 5, 4, 2, 5, 4, 4, 0, 0, 3, 4, 0, 3, 1, 4], device='cuda:0')\n","tensor([4, 0, 3, 4, 3, 3, 4, 3, 3, 4, 1, 4, 2, 0, 1, 2], device='cuda:0')\n","tensor([2, 3, 4, 2, 5, 4, 4, 0, 4, 0, 2, 0, 1, 1, 0, 5], device='cuda:0')\n","tensor([2, 4, 3, 2, 5, 4, 4, 1, 3, 1, 2, 4, 4, 5, 0, 3], device='cuda:0')\n","tensor([4, 0, 4, 2, 4, 0, 4, 1, 4, 3, 4, 5, 4, 2, 0, 4], device='cuda:0')\n","tensor([2, 3, 0, 4, 4, 1, 3, 5, 1, 2, 1, 4, 4, 4, 4, 5], device='cuda:0')\n","tensor([2, 4, 2, 3, 3, 0, 2, 3, 4, 0, 3, 2, 1, 2, 0, 2], device='cuda:0')\n","tensor([0, 4, 1, 4, 2, 2, 3, 2, 4, 4, 4, 4, 0, 4, 4, 0], device='cuda:0')\n","tensor([4, 1, 2, 1, 0, 0, 2, 4, 0, 0, 4, 4, 0, 4, 3, 0], device='cuda:0')\n","tensor([4, 0, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 3], device='cuda:0')\n","tensor([0, 3, 3, 2, 1, 4, 5, 4, 0, 3, 1, 2, 0, 2, 4, 1], device='cuda:0')\n","tensor([5, 1, 3, 4, 4, 3, 2, 2, 0, 4, 1, 0, 4, 2, 2, 4], device='cuda:0')\n","tensor([5, 0, 2, 2, 2, 1, 2, 2, 2, 4, 1, 5, 1, 2, 5, 4], device='cuda:0')\n","tensor([0, 4, 4, 2, 0, 4, 0, 4, 4, 1, 2, 4, 2, 3, 2, 3], device='cuda:0')\n","tensor([4, 1, 5, 4, 2, 2, 2, 1, 4, 4, 4, 4, 4, 1, 1, 0], device='cuda:0')\n","tensor([4, 0, 3, 5, 2, 4, 0, 2, 0, 4, 4, 5, 4, 2, 2, 1], device='cuda:0')\n","tensor([4, 4, 0, 4, 4, 0, 2, 2, 2, 3, 2, 4, 2, 4, 0, 4], device='cuda:0')\n","tensor([0, 5, 2, 0, 0, 4, 0, 2, 4, 2, 4, 2, 2, 2, 2, 2], device='cuda:0')\n","tensor([5, 0, 1, 4, 0, 0, 2, 4, 4, 0, 0, 2, 4, 4, 2, 4], device='cuda:0')\n","tensor([2, 4, 2, 4, 4, 5, 4, 3, 0, 1, 2, 4, 2, 1, 4, 0], device='cuda:0')\n","tensor([1, 4, 4, 3, 5, 1, 1, 4, 2, 0, 0, 4, 2, 2, 0, 2], device='cuda:0')\n","tensor([2, 2, 4, 0, 3, 2, 2, 4, 4, 4, 4, 4, 4, 5, 4, 4], device='cuda:0')\n","tensor([0, 0, 0, 4, 3, 2, 0, 4, 4, 2, 4, 2, 4, 4, 5, 4], device='cuda:0')\n","tensor([2, 0, 3, 5, 4, 2, 1, 0, 0, 2, 0, 2, 4, 0, 4, 5], device='cuda:0')\n","tensor([4, 0, 1, 0, 1, 4, 4, 0, 2, 1, 4, 0, 2, 2, 0, 4], device='cuda:0')\n","tensor([4, 0, 5, 2, 2, 4, 2, 3, 4, 4, 5, 1, 0, 4, 1, 5], device='cuda:0')\n","tensor([4, 2, 2, 4, 0, 5, 2, 3, 4, 3, 0, 0, 2, 5, 5, 4], device='cuda:0')\n","tensor([0, 4, 4, 1, 4, 0, 2, 1, 0, 2, 4, 1, 4, 2, 5, 4], device='cuda:0')\n","tensor([0, 4, 5, 0, 4, 0, 2, 0, 4, 0, 1, 4, 4, 4, 4, 0], device='cuda:0')\n","tensor([4, 4, 3, 3, 2, 2, 1, 0, 1, 4, 5, 4, 2, 2, 4, 2], device='cuda:0')\n","tensor([4, 2, 0, 0, 2, 0, 0, 1, 2, 5, 2, 5, 2, 1, 1, 1], device='cuda:0')\n","tensor([4, 4, 3, 0, 4, 4, 1, 2, 4, 4, 3, 2, 4, 4, 0, 5], device='cuda:0')\n","tensor([4, 4, 4, 1, 0, 0, 5, 0, 4, 0, 3, 2, 4, 4, 4, 5], device='cuda:0')\n","tensor([1, 0, 4, 0, 1, 4, 5, 4, 2, 4, 4, 4, 1, 5, 2, 1], device='cuda:0')\n","tensor([2, 4, 2, 3, 4, 1, 0, 1, 4, 5, 4, 2, 0, 2, 4, 3], device='cuda:0')\n","tensor([1, 0, 4, 4, 4, 5, 0, 3, 4, 4, 1, 4, 0, 5, 2, 2], device='cuda:0')\n","tensor([4, 0, 1, 4, 4, 0, 5, 2, 2, 2, 4, 0, 2, 0, 4, 2], device='cuda:0')\n","tensor([2, 2, 2, 3, 5, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 5], device='cuda:0')\n","tensor([4, 3, 0, 0, 4, 5, 3, 0, 4, 3, 3, 1, 4, 2, 2, 2], device='cuda:0')\n","tensor([2, 3, 1, 1, 3, 0, 5, 5, 4, 4, 4, 4, 0, 4, 4, 4], device='cuda:0')\n","tensor([0, 3, 4, 0, 0, 1, 3, 5, 4, 2, 4, 1, 5, 4, 0, 5], device='cuda:0')\n","tensor([2, 0, 1, 2, 1, 4, 4, 4, 0, 0, 2, 2, 4, 4, 4, 4], device='cuda:0')\n","tensor([4, 4, 1, 0, 0, 4, 0, 4, 0, 4, 1, 4, 4, 4, 4, 0], device='cuda:0')\n","tensor([2, 3, 0, 0, 3, 4, 2, 5, 4, 4, 0, 1, 3, 2, 4, 4], device='cuda:0')\n","tensor([5, 0, 4, 4, 0, 1, 2, 3, 5, 2, 4, 4, 2, 4, 2, 2], device='cuda:0')\n","tensor([3, 4, 4, 4, 2, 1, 0, 3, 4, 0, 1, 0, 0, 4, 4, 4], device='cuda:0')\n","tensor([4, 0, 2, 1, 4, 4, 4, 0, 4, 4, 2, 2, 2, 4, 1, 0], device='cuda:0')\n","tensor([1, 4, 1, 0, 2, 0, 2, 2, 4, 4, 1, 2, 4, 4, 3, 1], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 4, 4, 5, 2, 4, 0, 4, 0, 2, 0, 4], device='cuda:0')\n","tensor([3, 4, 4, 1, 1, 2, 4, 5, 4, 2, 0, 2, 3, 2, 2, 0], device='cuda:0')\n","tensor([1, 4, 4, 0, 5, 2, 3, 0, 4, 4, 3, 4, 4, 4, 4, 4], device='cuda:0')\n","tensor([3, 4, 3, 3, 3, 1, 4, 4, 4, 5, 2, 2, 2, 5, 4, 0], device='cuda:0')\n","tensor([5, 2, 2, 0, 2, 1, 2, 4, 2, 4, 0, 0, 2, 4, 2, 2], device='cuda:0')\n","tensor([3, 0, 4, 4, 4, 3, 2, 2, 4, 2, 4, 2, 4, 0, 3, 5], device='cuda:0')\n","tensor([1, 4, 4, 0, 1, 0, 0, 1, 2, 0, 3, 0, 2, 4, 4, 4], device='cuda:0')\n","tensor([2, 0, 5, 0, 3, 5, 0, 0, 4, 1, 4, 4, 3, 2, 0, 4], device='cuda:0')\n","tensor([5, 4, 5, 1, 2, 1, 4, 0, 4, 3, 4, 1, 4, 4, 4, 4], device='cuda:0')\n","tensor([1, 2, 0, 4, 1, 3, 4, 4, 2, 0, 1, 0, 1, 4, 2, 2], device='cuda:0')\n","tensor([4, 5, 5, 3, 2, 4, 2, 4, 4, 4, 2, 4, 4, 3, 3, 1], device='cuda:0')\n","tensor([1, 4, 4, 4, 2, 0, 4, 2, 4, 3, 0, 2], device='cuda:0')\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation took: 0:00:04\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","tensor([5, 4, 4, 4, 2, 2, 4, 4, 0, 2, 1, 1, 0, 4, 3, 5], device='cuda:0')\n","tensor([3, 3, 1, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4], device='cuda:0')\n","tensor([2, 5, 0, 4, 4, 2, 3, 4, 2, 5, 4, 2, 2, 2, 1, 2], device='cuda:0')\n","tensor([3, 5, 2, 1, 3, 0, 1, 5, 0, 4, 3, 4, 2, 0, 5, 4], device='cuda:0')\n","tensor([0, 2, 3, 4, 5, 3, 4, 4, 4, 4, 4, 4, 1, 4, 2, 3], device='cuda:0')\n","tensor([2, 4, 5, 1, 4, 2, 4, 4, 2, 1, 4, 0, 4, 4, 4, 2], device='cuda:0')\n","tensor([1, 2, 2, 1, 2, 1, 0, 2, 2, 0, 4, 4, 0, 2, 2, 2], device='cuda:0')\n","tensor([2, 4, 4, 0, 0, 3, 0, 3, 2, 0, 5, 4, 0, 4, 4, 4], device='cuda:0')\n","tensor([0, 1, 2, 4, 0, 2, 3, 2, 3, 3, 3, 2, 5, 4, 0, 0], device='cuda:0')\n","tensor([2, 2, 2, 4, 1, 4, 3, 3, 0, 1, 3, 2, 1, 0, 4, 4], device='cuda:0')\n","tensor([5, 2, 3, 1, 1, 4, 4, 2, 0, 2, 0, 1, 0, 0, 4, 4], device='cuda:0')\n","tensor([1, 4, 4, 5, 1, 1, 2, 1, 0, 4, 4, 4, 2, 4, 1, 3], device='cuda:0')\n","tensor([1, 4, 2, 3, 1, 0, 4, 4, 4, 4, 2, 4, 5, 1, 0, 4], device='cuda:0')\n","tensor([4, 1, 0, 4, 4, 2, 1, 4, 2, 4, 3, 0, 4, 0, 4, 0], device='cuda:0')\n","tensor([4, 0, 3, 0, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4], device='cuda:0')\n","tensor([1, 5, 3, 4, 3, 3, 4, 0, 4, 0, 2, 4, 0, 2, 2, 1], device='cuda:0')\n","tensor([4, 5, 4, 3, 4, 4, 4, 3, 2, 3, 2, 4, 4, 1, 2, 4], device='cuda:0')\n","tensor([4, 0, 0, 2, 0, 2, 0, 5, 4, 3, 4, 1, 2, 4, 2, 4], device='cuda:0')\n","tensor([0, 2, 2, 4, 2, 4, 0, 0, 2, 4, 5, 5, 0, 3, 3, 4], device='cuda:0')\n","tensor([4, 0, 4, 4, 4, 4, 4, 5, 2, 2, 1, 4, 4, 2, 5, 3], device='cuda:0')\n","tensor([4, 2, 2, 3, 0, 4, 4, 4, 4, 4, 3, 4, 2, 1, 1, 0], device='cuda:0')\n","tensor([2, 4, 0, 3, 1, 4, 3, 1, 2, 2, 1, 2, 0, 1, 5, 2], device='cuda:0')\n","tensor([3, 2, 2, 4, 0, 5, 4, 5, 4, 4, 4, 2, 0, 0, 2, 2], device='cuda:0')\n","tensor([4, 0, 2, 1, 0, 0, 2, 2, 2, 4, 4, 4, 5, 0, 2, 3], device='cuda:0')\n","tensor([2, 4, 4, 3, 3, 2, 2, 4, 4, 2, 5, 4, 4, 1, 0, 3], device='cuda:0')\n","tensor([4, 2, 0, 0, 0, 4, 5, 5, 0, 4, 2, 0, 4, 1, 5, 0], device='cuda:0')\n","tensor([1, 4, 5, 4, 4, 4, 3, 2, 4, 4, 0, 4, 4, 4, 0, 4], device='cuda:0')\n","tensor([3, 2, 5, 4, 4, 4, 4, 1, 4, 4, 1, 3, 0, 2, 0, 4], device='cuda:0')\n","tensor([1, 4, 5, 4, 0, 1, 0, 2, 4, 1, 4, 5, 2, 2, 0, 0], device='cuda:0')\n","tensor([2, 2, 4, 4, 4, 2, 1, 0, 2, 5, 4, 2, 2, 2, 4, 0], device='cuda:0')\n","tensor([5, 4, 0, 3, 2, 4, 1, 0, 2, 4, 1, 5, 4, 1, 2, 4], device='cuda:0')\n","tensor([0, 4, 0, 4, 2, 0, 1, 0, 4, 0, 0, 5, 5, 0, 4, 1], device='cuda:0')\n","tensor([5, 2, 4, 4, 0, 1, 3, 0, 4, 4, 2, 1, 4, 0, 2, 4], device='cuda:0')\n","tensor([4, 4, 0, 4, 4, 4, 0, 4, 4, 3, 4, 3, 2, 2, 4, 0], device='cuda:0')\n","tensor([4, 2, 5, 4, 0, 3, 4, 5, 2, 1, 0, 5, 2, 3, 5, 0], device='cuda:0')\n","tensor([2, 1, 4, 1, 1, 4, 0, 4, 4, 4, 4, 0, 0, 4, 4, 2], device='cuda:0')\n","tensor([0, 4, 3, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2, 0, 3, 4], device='cuda:0')\n","tensor([2, 1, 2, 4, 1, 0, 2, 0, 4, 5, 4, 2, 1, 4, 0, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 0, 1, 2, 4, 4, 4, 0, 4, 2, 2, 0, 5], device='cuda:0')\n","tensor([3, 4, 2, 2, 1, 4, 0, 5, 2, 1, 4, 4, 1, 2, 4, 4], device='cuda:0')\n","tensor([2, 3, 3, 4, 3, 2, 5, 2, 0, 4, 0, 0, 5, 4, 4, 4], device='cuda:0')\n","tensor([3, 3, 5, 4, 4, 0, 2, 0, 0, 4, 0, 4, 2, 5, 2, 4], device='cuda:0')\n","tensor([2, 0, 0, 0, 0, 1, 4, 5, 0, 4, 1, 0, 4, 2, 1, 4], device='cuda:0')\n","tensor([0, 4, 2, 2, 4, 2, 0, 4, 4, 5, 2, 4, 3, 3, 4, 5], device='cuda:0')\n","tensor([3, 3, 4, 4, 3, 4, 2, 0, 4, 5, 2, 1, 0, 5, 4, 4], device='cuda:0')\n","tensor([4, 1, 3, 1, 3, 2, 2, 4, 4, 2, 2, 4, 3, 2, 3, 3], device='cuda:0')\n","tensor([4, 2, 4, 4, 5, 1, 3, 2, 2, 2, 2, 2, 4, 2, 4, 4], device='cuda:0')\n","tensor([0, 4, 3, 5, 4, 4, 0, 1, 4, 1, 0, 0, 2, 2, 0, 4], device='cuda:0')\n","tensor([4, 1, 4, 4, 4, 5, 3, 4, 0, 4, 2, 2, 4, 2, 0, 4], device='cuda:0')\n","tensor([1, 5, 4, 0, 2, 2, 4, 3, 4, 1, 1, 4, 4, 0, 4, 2], device='cuda:0')\n","tensor([4, 2, 0, 5, 5, 0, 4, 0, 5, 2, 2, 4, 1, 0, 4, 1], device='cuda:0')\n","tensor([3, 0, 4, 0, 3, 1, 2, 5, 1, 2, 4, 0, 2, 5, 0, 2], device='cuda:0')\n","tensor([4, 0, 1, 4, 0, 1, 1, 0, 4, 4, 4, 4, 4, 3, 4, 0], device='cuda:0')\n","tensor([2, 1, 0, 2, 2, 0, 2, 2, 3, 0, 0, 5, 5, 3, 0, 2], device='cuda:0')\n","tensor([4, 1, 0, 5, 4, 1, 0, 3, 0, 4, 4, 4, 4, 0, 0, 0], device='cuda:0')\n","tensor([4, 4, 4, 5, 0, 4, 4, 4, 0, 1, 4, 0, 4, 2, 1, 2], device='cuda:0')\n","tensor([0, 4, 4, 4, 4, 1, 1, 1, 1, 0, 2, 2, 2, 3, 4, 4], device='cuda:0')\n","tensor([2, 0, 0, 2, 1, 0, 4, 2, 2, 2, 2, 4, 4, 2, 0, 0], device='cuda:0')\n","tensor([2, 0, 0, 1, 4, 4, 2, 2, 3, 0, 4, 4, 4, 4, 4, 4], device='cuda:0')\n","tensor([4, 4, 2, 4, 4, 0, 2, 5, 2, 4, 1, 2], device='cuda:0')\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation took: 0:00:04\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","tensor([2, 2, 4, 4, 4, 4, 4, 0, 1, 4, 4, 0, 4, 1, 3, 2], device='cuda:0')\n","tensor([0, 2, 5, 1, 2, 0, 2, 4, 2, 4, 3, 4, 4, 4, 0, 3], device='cuda:0')\n","tensor([2, 4, 4, 0, 4, 4, 4, 5, 5, 4, 2, 1, 4, 4, 4, 1], device='cuda:0')\n","tensor([0, 2, 0, 3, 1, 0, 1, 3, 5, 4, 4, 4, 0, 4, 4, 4], device='cuda:0')\n","tensor([0, 0, 2, 0, 4, 3, 1, 4, 4, 0, 1, 4, 0, 5, 0, 2], device='cuda:0')\n","tensor([2, 4, 0, 1, 5, 4, 2, 4, 2, 2, 4, 0, 0, 2, 4, 3], device='cuda:0')\n","tensor([0, 5, 0, 5, 0, 3, 4, 0, 3, 2, 0, 2, 0, 1, 1, 3], device='cuda:0')\n","tensor([0, 4, 4, 1, 0, 4, 4, 4, 4, 4, 4, 5, 4, 2, 4, 4], device='cuda:0')\n","tensor([2, 4, 0, 5, 0, 0, 4, 3, 0, 2, 4, 2, 0, 3, 2, 2], device='cuda:0')\n","tensor([4, 4, 5, 3, 2, 5, 2, 0, 0, 0, 4, 2, 4, 4, 0, 4], device='cuda:0')\n","tensor([4, 2, 2, 2, 4, 4, 2, 2, 5, 3, 4, 3, 2, 1, 1, 4], device='cuda:0')\n","tensor([1, 4, 0, 4, 4, 4, 5, 0, 4, 2, 4, 4, 2, 0, 4, 4], device='cuda:0')\n","tensor([2, 4, 4, 2, 4, 0, 5, 2, 4, 2, 4, 4, 4, 0, 1, 4], device='cuda:0')\n","tensor([3, 2, 5, 0, 5, 4, 3, 2, 5, 4, 4, 4, 4, 2, 1, 3], device='cuda:0')\n","tensor([4, 4, 2, 0, 3, 4, 4, 0, 2, 1, 4, 1, 4, 0, 5, 4], device='cuda:0')\n","tensor([4, 1, 0, 4, 2, 4, 4, 3, 0, 2, 4, 4, 2, 2, 4, 1], device='cuda:0')\n","tensor([1, 4, 2, 4, 4, 4, 0, 2, 0, 4, 4, 3, 1, 3, 4, 0], device='cuda:0')\n","tensor([4, 2, 4, 4, 0, 0, 2, 4, 2, 0, 4, 3, 4, 0, 0, 1], device='cuda:0')\n","tensor([1, 5, 0, 2, 2, 1, 1, 5, 1, 0, 3, 3, 0, 0, 2, 2], device='cuda:0')\n","tensor([4, 4, 0, 3, 4, 4, 0, 2, 4, 0, 4, 2, 1, 4, 4, 0], device='cuda:0')\n","tensor([2, 1, 4, 4, 1, 1, 3, 1, 0, 5, 1, 1, 3, 3, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 4, 5, 4, 4, 2, 2, 1, 0, 4, 0, 4, 2, 4], device='cuda:0')\n","tensor([1, 4, 2, 0, 4, 4, 0, 3, 1, 0, 2, 0, 5, 2, 4, 4], device='cuda:0')\n","tensor([2, 4, 2, 2, 4, 4, 1, 2, 4, 4, 0, 0, 3, 4, 3, 0], device='cuda:0')\n","tensor([4, 4, 0, 0, 3, 2, 4, 5, 2, 0, 2, 5, 4, 3, 1, 3], device='cuda:0')\n","tensor([2, 4, 1, 0, 4, 4, 4, 5, 2, 1, 4, 0, 2, 5, 1, 0], device='cuda:0')\n","tensor([4, 2, 1, 4, 4, 4, 3, 2, 0, 0, 4, 5, 2, 2, 0, 2], device='cuda:0')\n","tensor([5, 2, 4, 0, 2, 4, 3, 4, 4, 5, 0, 2, 4, 4, 4, 3], device='cuda:0')\n","tensor([1, 0, 0, 0, 5, 3, 4, 1, 1, 0, 0, 4, 4, 2, 0, 4], device='cuda:0')\n","tensor([0, 0, 4, 2, 4, 4, 5, 1, 1, 4, 0, 5, 3, 2, 4, 2], device='cuda:0')\n","tensor([4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 1, 4, 0, 1, 0], device='cuda:0')\n","tensor([4, 4, 0, 1, 2, 0, 0, 2, 2, 4, 0, 1, 2, 2, 4, 0], device='cuda:0')\n","tensor([4, 4, 4, 2, 4, 2, 2, 0, 3, 5, 4, 3, 0, 0, 4, 2], device='cuda:0')\n","tensor([2, 4, 2, 0, 2, 4, 3, 1, 3, 0, 4, 4, 4, 4, 4, 5], device='cuda:0')\n","tensor([1, 4, 2, 0, 4, 4, 1, 3, 1, 2, 4, 2, 4, 2, 0, 2], device='cuda:0')\n","tensor([4, 4, 4, 0, 5, 4, 4, 2, 1, 2, 4, 4, 2, 4, 4, 1], device='cuda:0')\n","tensor([2, 0, 4, 5, 4, 0, 5, 2, 2, 0, 2, 2, 3, 2, 3, 4], device='cuda:0')\n","tensor([0, 1, 2, 1, 4, 3, 2, 3, 3, 0, 0, 0, 0, 1, 5, 4], device='cuda:0')\n","tensor([4, 2, 5, 4, 4, 2, 4, 1, 5, 2, 2, 3, 2, 4, 4, 2], device='cuda:0')\n","tensor([4, 0, 0, 3, 2, 4, 4, 4, 3, 3, 2, 0, 4, 3, 4, 5], device='cuda:0')\n","tensor([0, 4, 5, 4, 4, 4, 2, 2, 1, 2, 2, 0, 2, 4, 4, 0], device='cuda:0')\n","tensor([2, 4, 4, 5, 4, 1, 2, 5, 2, 1, 0, 4, 4, 2, 1, 0], device='cuda:0')\n","tensor([4, 2, 4, 4, 3, 2, 2, 0, 2, 2, 3, 4, 0, 3, 1, 4], device='cuda:0')\n","tensor([4, 4, 0, 4, 4, 1, 2, 5, 4, 0, 4, 0, 4, 5, 4, 3], device='cuda:0')\n","tensor([2, 2, 2, 4, 5, 4, 4, 3, 2, 4, 4, 4, 4, 2, 4, 0], device='cuda:0')\n","tensor([5, 4, 4, 1, 2, 0, 1, 1, 1, 4, 4, 4, 4, 5, 0, 0], device='cuda:0')\n","tensor([2, 2, 3, 2, 4, 4, 2, 2, 4, 0, 4, 2, 1, 2, 5, 0], device='cuda:0')\n","tensor([4, 0, 4, 2, 2, 2, 0, 0, 3, 0, 2, 4, 3, 5, 3, 1], device='cuda:0')\n","tensor([4, 4, 4, 1, 2, 0, 4, 4, 1, 4, 4, 4, 4, 0, 1, 4], device='cuda:0')\n","tensor([4, 1, 5, 1, 2, 1, 4, 0, 0, 1, 3, 0, 2, 2, 2, 3], device='cuda:0')\n","tensor([0, 2, 0, 1, 5, 4, 4, 4, 2, 2, 0, 2, 2, 0, 4, 1], device='cuda:0')\n","tensor([4, 4, 2, 4, 2, 0, 5, 0, 1, 4, 2, 4, 4, 5, 1, 1], device='cuda:0')\n","tensor([2, 1, 4, 4, 1, 2, 4, 4, 5, 0, 1, 2, 0, 1, 0, 2], device='cuda:0')\n","tensor([0, 5, 0, 2, 1, 5, 5, 4, 2, 2, 4, 2, 0, 2, 2, 3], device='cuda:0')\n","tensor([3, 0, 4, 4, 4, 0, 2, 3, 2, 4, 3, 4, 4, 0, 2, 2], device='cuda:0')\n","tensor([4, 0, 5, 2, 0, 4, 0, 3, 4, 2, 4, 2, 1, 5, 0, 5], device='cuda:0')\n","tensor([4, 2, 2, 4, 3, 4, 0, 3, 1, 1, 2, 3, 2, 0, 1, 4], device='cuda:0')\n","tensor([0, 2, 3, 5, 4, 3, 2, 3, 2, 4, 1, 4, 4, 1, 4, 4], device='cuda:0')\n","tensor([2, 3, 3, 4, 3, 0, 3, 4, 4, 5, 4, 4, 4, 5, 5, 0], device='cuda:0')\n","tensor([3, 2, 1, 4, 3, 4, 5, 4, 4, 4, 4, 4], device='cuda:0')\n","\n","  Average training loss: 0.13\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation took: 0:00:04\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","tensor([0, 0, 4, 5, 0, 4, 0, 4, 4, 4, 3, 4, 4, 5, 2, 4], device='cuda:0')\n","tensor([4, 2, 0, 0, 0, 4, 5, 2, 4, 5, 4, 4, 2, 1, 3, 2], device='cuda:0')\n","tensor([1, 2, 3, 0, 4, 0, 3, 1, 1, 1, 4, 4, 4, 2, 4, 5], device='cuda:0')\n","tensor([4, 4, 2, 5, 4, 4, 4, 4, 2, 4, 5, 4, 3, 4, 2, 5], device='cuda:0')\n","tensor([1, 2, 0, 0, 4, 5, 3, 3, 3, 4, 4, 2, 5, 4, 1, 3], device='cuda:0')\n","tensor([4, 4, 4, 4, 4, 1, 3, 4, 5, 5, 2, 4, 3, 1, 2, 0], device='cuda:0')\n","tensor([3, 5, 5, 4, 3, 0, 4, 4, 4, 0, 4, 4, 2, 5, 0, 4], device='cuda:0')\n","tensor([0, 2, 4, 1, 1, 4, 4, 1, 4, 2, 4, 0, 0, 0, 4, 2], device='cuda:0')\n","tensor([4, 0, 2, 4, 4, 1, 4, 2, 0, 4, 4, 0, 2, 1, 4, 4], device='cuda:0')\n","tensor([2, 0, 1, 4, 2, 4, 2, 2, 0, 1, 1, 4, 2, 3, 2, 4], device='cuda:0')\n","tensor([0, 2, 4, 1, 4, 2, 0, 5, 5, 2, 0, 1, 0, 3, 5, 2], device='cuda:0')\n","tensor([4, 1, 2, 3, 3, 2, 0, 0, 4, 2, 1, 3, 0, 2, 2, 5], device='cuda:0')\n","tensor([0, 4, 4, 0, 1, 3, 5, 2, 1, 4, 1, 3, 4, 4, 4, 2], device='cuda:0')\n","tensor([3, 0, 0, 4, 0, 0, 0, 1, 0, 4, 3, 4, 4, 4, 4, 4], device='cuda:0')\n","tensor([5, 1, 2, 2, 0, 2, 1, 5, 5, 4, 3, 0, 3, 4, 4, 1], device='cuda:0')\n","tensor([4, 3, 4, 4, 0, 4, 4, 3, 1, 0, 2, 4, 4, 0, 2, 4], device='cuda:0')\n","tensor([4, 4, 1, 0, 2, 1, 4, 0, 1, 2, 4, 2, 4, 2, 4, 0], device='cuda:0')\n","tensor([4, 0, 4, 4, 0, 2, 4, 1, 0, 4, 2, 2, 2, 2, 2, 4], device='cuda:0')\n","tensor([2, 0, 5, 4, 4, 0, 4, 5, 4, 2, 2, 2, 1, 0, 2, 4], device='cuda:0')\n","tensor([4, 0, 4, 0, 4, 1, 5, 3, 4, 4, 2, 5, 1, 2, 5, 1], device='cuda:0')\n","tensor([4, 0, 4, 3, 1, 2, 2, 0, 4, 4, 0, 3, 4, 4, 5, 2], device='cuda:0')\n","tensor([0, 4, 1, 2, 2, 2, 5, 1, 4, 4, 2, 1, 4, 3, 5, 0], device='cuda:0')\n","tensor([4, 4, 2, 2, 0, 2, 4, 4, 2, 1, 2, 4, 4, 3, 4, 2], device='cuda:0')\n","tensor([4, 3, 3, 4, 1, 0, 4, 4, 2, 3, 2, 0, 3, 2, 4, 2], device='cuda:0')\n","tensor([1, 0, 2, 0, 4, 4, 4, 3, 2, 4, 0, 4, 3, 0, 2, 4], device='cuda:0')\n","tensor([2, 0, 2, 1, 2, 0, 4, 4, 0, 3, 4, 4, 0, 4, 2, 5], device='cuda:0')\n","tensor([2, 1, 1, 4, 0, 0, 4, 3, 4, 3, 4, 4, 3, 1, 0, 0], device='cuda:0')\n","tensor([4, 1, 4, 3, 2, 0, 2, 1, 2, 4, 2, 0, 3, 2, 0, 2], device='cuda:0')\n","tensor([2, 2, 4, 2, 0, 4, 2, 4, 0, 4, 4, 4, 1, 0, 4, 3], device='cuda:0')\n","tensor([3, 4, 4, 0, 3, 1, 2, 0, 4, 4, 3, 4, 2, 2, 4, 4], device='cuda:0')\n","tensor([3, 4, 2, 4, 2, 4, 4, 0, 3, 4, 2, 4, 5, 0, 0, 0], device='cuda:0')\n","tensor([2, 1, 5, 0, 5, 2, 5, 4, 4, 4, 4, 4, 4, 4, 4, 0], device='cuda:0')\n","tensor([3, 4, 4, 4, 5, 4, 0, 0, 1, 4, 0, 2, 5, 4, 0, 1], device='cuda:0')\n","tensor([0, 4, 0, 0, 0, 3, 2, 4, 4, 3, 4, 4, 0, 3, 4, 4], device='cuda:0')\n","tensor([4, 4, 4, 2, 5, 0, 4, 4, 2, 0, 3, 2, 0, 4, 2, 4], device='cuda:0')\n","tensor([1, 5, 4, 3, 2, 0, 4, 4, 4, 0, 4, 1, 3, 4, 4, 4], device='cuda:0')\n","tensor([3, 4, 2, 1, 2, 4, 0, 4, 4, 2, 3, 4, 2, 0, 4, 4], device='cuda:0')\n","tensor([2, 3, 5, 2, 1, 2, 2, 0, 0, 4, 4, 1, 4, 4, 3, 5], device='cuda:0')\n","tensor([1, 2, 4, 1, 4, 0, 4, 0, 0, 1, 0, 2, 2, 4, 2, 4], device='cuda:0')\n","tensor([4, 5, 4, 3, 2, 1, 4, 4, 5, 2, 2, 1, 4, 4, 4, 4], device='cuda:0')\n","tensor([2, 3, 3, 1, 2, 0, 0, 2, 2, 4, 4, 3, 4, 2, 2, 4], device='cuda:0')\n","tensor([2, 2, 1, 1, 2, 3, 4, 4, 2, 0, 1, 2, 3, 5, 0, 2], device='cuda:0')\n","tensor([0, 4, 4, 4, 2, 2, 1, 4, 4, 2, 3, 0, 1, 4, 4, 2], device='cuda:0')\n","tensor([1, 1, 5, 0, 2, 5, 0, 4, 4, 1, 2, 2, 5, 2, 0, 5], device='cuda:0')\n","tensor([4, 0, 4, 4, 3, 2, 4, 1, 4, 0, 4, 4, 2, 1, 4, 0], device='cuda:0')\n","tensor([2, 2, 2, 3, 2, 4, 2, 2, 4, 0, 4, 2, 4, 2, 0, 4], device='cuda:0')\n","tensor([2, 4, 2, 4, 4, 4, 1, 0, 3, 4, 5, 2, 0, 0, 1, 4], device='cuda:0')\n","tensor([1, 2, 0, 2, 4, 0, 0, 5, 2, 0, 2, 1, 2, 4, 1, 2], device='cuda:0')\n","tensor([3, 4, 1, 4, 0, 2, 4, 4, 1, 4, 4, 4, 2, 4, 0, 0], device='cuda:0')\n","tensor([0, 0, 4, 0, 0, 2, 4, 3, 5, 5, 2, 0, 4, 5, 3, 1], device='cuda:0')\n","tensor([1, 4, 4, 0, 2, 3, 1, 2, 4, 5, 3, 4, 0, 1, 2, 4], device='cuda:0')\n","tensor([4, 1, 2, 4, 4, 2, 3, 5, 4, 4, 1, 4, 0, 2, 4, 4], device='cuda:0')\n","tensor([4, 2, 4, 0, 4, 0, 0, 2, 5, 5, 2, 2, 4, 1, 0, 2], device='cuda:0')\n","tensor([0, 0, 3, 2, 2, 4, 4, 2, 4, 3, 5, 1, 1, 2, 4, 4], device='cuda:0')\n","tensor([2, 4, 5, 5, 4, 5, 2, 2, 2, 0, 0, 4, 0, 2, 0, 4], device='cuda:0')\n","tensor([0, 5, 3, 1, 0, 4, 4, 1, 5, 0, 4, 4, 2, 2, 4, 4], device='cuda:0')\n","tensor([2, 4, 4, 1, 4, 2, 0, 4, 4, 4, 3, 4, 0, 2, 1, 0], device='cuda:0')\n","tensor([5, 0, 5, 1, 5, 2, 2, 4, 4, 2, 5, 4, 3, 0, 0, 3], device='cuda:0')\n","tensor([0, 4, 4, 4, 1, 4, 1, 4, 4, 0, 0, 0, 1, 4, 2, 0], device='cuda:0')\n","tensor([3, 4, 4, 2, 5, 2, 2, 4, 2, 2, 0, 4], device='cuda:0')\n","\n","  Average training loss: 0.10\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation took: 0:00:04\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHQAxxhKZH7G","executionInfo":{"status":"ok","timestamp":1620332487971,"user_tz":-540,"elapsed":535641,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"4a877f7a-2450-44b9-f1b2-ad8460beea73"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Accuracy: 0.71\n","Test took: 0:00:05\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXf79de-ZNbT"},"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 128\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDZ-tRLvZQVL"},"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ktGvJFxDZU_N"},"source":["# 문자열 입력"]},{"cell_type":"code","metadata":{"id":"pSvrpYqQy_bq"},"source":["# 'anger', 'fear', 'joy', 'love', 'sadness', 'surprise'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dnP1IymZT-j"},"source":["# 딕셔너리\n","sentiment_dic = {\n","    0 : 'anger',\n","    1 : 'fear',\n","    2 : 'joy',\n","    3 : 'love',\n","    4 : 'sadness',\n","    5 : 'surprise',\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXYUwhvtZkm6","executionInfo":{"status":"ok","timestamp":1620332487976,"user_tz":-540,"elapsed":535609,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"3c5f37a6-5daa-4d3a-868a-e037d2a9e683"},"source":["logits = test_sentences(['연기는 별로지만 재미하나는 끝내준다'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])\n","label_encoder.classes_\n","# label_encoder.inverse_transform(sentiment)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.6169816  -1.0904454   0.09895465  0.93315315  3.5801294  -1.3586738\n","  -1.4137205 ]]\n","sadness\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array(['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHP1k--fZm3p","executionInfo":{"status":"ok","timestamp":1620332487976,"user_tz":-540,"elapsed":535601,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"74978424-59af-4f75-853c-68312033cce9"},"source":["logits = test_sentences(['오랜만에 할일도 없고 우울하다.'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.6204619  -1.0780472  -0.97172326  0.00713748  4.9217205  -0.848249\n","  -0.84466475]]\n","sadness\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwCHWBodZpTk","executionInfo":{"status":"ok","timestamp":1620333103959,"user_tz":-540,"elapsed":1325,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"dc5ef8e4-c398-4067-9d34-f32246be5c62"},"source":["\n","logits = test_sentences(['✨4월 28일 개발일지✨ # 오늘의 프로젝트 진행 1. 크롤링 버그 수정 2. WBS 수정 중   # 오늘의 소감 교양 시험이 수요일부로 끝나서 모든 중간고사가 끝났다.  이제 다시 캡스톤 디자인에 집중할 수 있을거 같다.  WBS도 데모버전까지만 만들어놓았는데 이제 추가해줘야겠다. 데이터도 손봐야한다. 레이블이 다르기 때문에, 통합해줘서 백엔드로 넘겨주고 싶다. 이번 주까지 끝내는 게 목표다.🔥 다음주부터는 모델에 학습 시키고 그걸 PPT만들어서 개인발표해야한다. 그때 좋은 결과물이 만들어지는게 내 바램이다~~'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.57320267 -0.6923969   4.438226   -1.1045177  -0.80930096 -0.6180905\n","  -0.94409764]]\n","joy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwq0El6PZq2W","executionInfo":{"status":"ok","timestamp":1620332487978,"user_tz":-540,"elapsed":535585,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"613ee5e9-a135-43b5-9ce6-7725a8822d05"},"source":["logits = test_sentences(['아무것다 하기 싫다. 우울하다 ㅠㅠ'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.73473245 -0.97583956 -0.92586535 -0.0892795   4.8351936  -0.57447505\n","  -0.9959212 ]]\n","sadness\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q6z_dnqx32lu","executionInfo":{"status":"ok","timestamp":1620332487978,"user_tz":-540,"elapsed":535577,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"a7060cf8-3dd7-4b71-aa83-8ad469d062c0"},"source":["logits = test_sentences(['4월 14일 개발일지 오늘의 소감 Api 없이 인스타그램에서 아이디와 비밀번호를 입력하면 내가 올린 게시물을 종류별로 정리해서 csv 파일로 저장하는 코드를 완성했다. 사실 이것도 많이 늦은거라 팀원들에게 미안하다..ㅠㅠ 이번주는 개인 개발 뿐만이 아니라 발표까지 해야하기때문에 더더욱 바쁘다..그래도 힘내서 좋은 결과물이 나올수 있게 노력해야겠다!'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-0.35428563 -0.69404024  4.543234   -1.1380832  -1.1653237  -0.7728045\n","  -0.8999353 ]]\n","joy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIK9rKwW4C_L","executionInfo":{"status":"ok","timestamp":1620332488341,"user_tz":-540,"elapsed":535933,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"fb79458f-6f8c-4637-9c9e-0d8da867c01a"},"source":["logits = test_sentences(['4월 13일 개발일지 오늘의 소감 db에 있는 값을 계산하여 통계를 내보았다. 잘안되서 화났다. 이미지로 저장해서 웹페이지에 로드를 하는 방법이라 동적으로 나타나게 하려면 chart.js 를 사용해서 구현을 해야할것 같기도 하다! 두가지 방법을 시도해봐야겠다 생각한만큼 구현해낼수 있으면 좋은데 힘들다...'])\n","\n","print(logits)\n","print(sentiment_dic[np.argmax(logits)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 3.2342293  -0.54977226  1.2824624  -1.6213567  -1.0619576  -0.37224793\n","  -1.2290378 ]]\n","anger\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yk6Nd2l3Zwud"},"source":["#전처리"]},{"cell_type":"code","metadata":{"id":"yvTVP2EqZxa5"},"source":["df[\"text\"] = df[\"text\"].apply(lambda x: clean_str(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6kgwjbzZ0hU"},"source":["#예측"]},{"cell_type":"code","metadata":{"id":"ow-JI6LDZzEj"},"source":["#df[\"pred\"] = df[\"text\"].apply(lambda x: sentiment_dic[np.argmax(test_sentences([x]))])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gQMBm1BNZ51m"},"source":["#df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvJ8OLVJZ2pU"},"source":["\n","#df[df[\"sentiment\"] == df[\"pred\"]][\"sentiment\"].value_counts().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIYn7Sp9Z6zB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"waRwkW10Z6ty"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9GidDVqZ8nR"},"source":["# 모델 저장하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1x_FCOjZ963","executionInfo":{"status":"ok","timestamp":1620332588810,"user_tz":-540,"elapsed":3484,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"0702f9dd-e7fa-47b1-a77c-1af64ff9bc7e"},"source":["import os\n","\n","output_dir = './model_save/'\n","if not os.path.exists(output_dir):\n","   os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to ./model_save/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./model_save/tokenizer_config.json',\n"," './model_save/special_tokens_map.json',\n"," './model_save/vocab.txt',\n"," './model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":132}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vc4Bdk10aCCI","executionInfo":{"status":"ok","timestamp":1620332592526,"user_tz":-540,"elapsed":659,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"af45ce42-f07c-43a5-d323-9700a7de9971"},"source":["!ls -l --block-size=K ./model_save/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 695844K\n","-rw-r--r-- 1 root root      2K May  6 20:23 config.json\n","-rw-r--r-- 1 root root 694849K May  6 20:23 pytorch_model.bin\n","-rw-r--r-- 1 root root      1K May  6 20:23 special_tokens_map.json\n","-rw-r--r-- 1 root root      1K May  6 20:23 tokenizer_config.json\n","-rw-r--r-- 1 root root    973K May  6 20:23 vocab.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EatlqJ-XaCfJ","executionInfo":{"status":"ok","timestamp":1620332594843,"user_tz":-540,"elapsed":618,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"05233501-6d32-406a-e44e-36779bf25f6d"},"source":["!ls -l --block-size=M ./model_save/pytorch_model.bin"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 679M May  6 20:23 ./model_save/pytorch_model.bin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKEHdJlRaJdU","executionInfo":{"status":"ok","timestamp":1620332597186,"user_tz":-540,"elapsed":634,"user":{"displayName":"김신영","photoUrl":"","userId":"11478318935090756381"}},"outputId":"9adc8138-257d-4cfd-e523-f2e993b8809f"},"source":["# Mount Google Drive to this Notebook instance.\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BJdsAWLVaRZj"},"source":["# Copy the model files to a directory in your Google Drive.\n","\n","!cp -r ./model_save/ \"/content/drive/MyDrive/캡스톤디자인/BERT Fine-Tuning/\""],"execution_count":null,"outputs":[]}]}